[ { "title": "HackerRank SQL 문제", "url": "/posts/hackerrank_sql/", "categories": "DB", "tags": "SQL, DB", "date": "2022-02-24 00:00:00 +0900", "snippet": "SQL Project PlanningWITHstart AS ( SELECT Start_Date, ROW_NUMBER() OVER(ORDER BY Start_Date) AS rn FROM Projects WHERE Start_date NOT in (SELECT End_Date FROM Projects)), end AS ( SELECT End_Date, ROW_NUMBER() OVER(ORDER BY End_Date) AS rn FROM Projects WHERE End_Date NOT in (SELECT Start_Date FROM Projects))SELECT start.Start_Date, end.End_DateFROM start JOIN end ON start.rn=end.rnORDER BY DATEDIFF(end.End_Date, start.Start_Date), start.Start_DateSymmetric Pairs(5, 5) 처럼 X와 Y가 같은 값은 두 개 이상 있어야 pair가 되므로 COUNT(a.X) &amp;gt; 1가 필요합니다.SELECT a.X, a.YFROM Functions a JOIN Functions b ON a.Y=b.X AND a.X=b.YGROUP BY a.X, a.YHAVING COUNT(a.X) &amp;gt; 1 OR a.X &amp;lt; a.YORDER BY a.X, a.YThe ReportSELECT CASE WHEN b.Grade &amp;gt;= 8 THEN a.Name ELSE &#39;NULL&#39; END , b.Grade , a.MarksFROM Students a JOIN Grades b ON b.Min_Mark &amp;lt;= a.Marks AND a.Marks &amp;lt;= b.Max_MarkORDER BY b.Grade DESC, a.Name, a.Marks DESCChallengesSELECT hacker_id , name , challenges_createdFROM ( SELECT h.hacker_id AS hacker_id , h.name AS name , COUNT(*) AS challenges_created FROM Challenges c JOIN Hackers h ON c.hacker_id=h.hacker_id GROUP BY h.hacker_id, h.name ORDER BY challenges_created DESC, h.hacker_id) retWHERE challenges_created = ( SELECT MAX(challenges_created) FROM ( SELECT hacker_id , COUNT(*) AS challenges_created FROM Challenges GROUP BY hacker_id ) r1) OR challenges_created IN ( SELECT challenges_created FROM ( SELECT hacker_id , COUNT(*) AS challenges_created FROM Challenges GROUP BY hacker_id ) r2 GROUP BY challenges_created HAVING COUNT(*)=1)The PADS( SELECT msg FROM ( SELECT Name , CONCAT(Name, &#39;(&#39;, SUBSTR(Occupation, 1, 1), &#39;)&#39;) AS msg FROM OCCUPATIONS ORDER BY Name ) r1)UNION ALL( SELECT msg FROM ( SELECT COUNT(*) as num , CONCAT( &#39;There are a total of &#39; , COUNT(*) , &#39; &#39; , LOWER(Occupation) , &#39;s.&#39; ) AS msg FROM OCCUPATIONS GROUP BY Occupation ORDER BY num DESC, msg ) r2)이렇게 했으나, UNION ALL 단계에서 정렬이 풀렸다.SELECT msgFROM( ( SELECT msg , 1 AS filter1 , ROW_NUMBER() OVER(ORDER BY Name) AS filter2 FROM ( SELECT Name , CONCAT(Name, &#39;(&#39;, SUBSTR(Occupation, 1, 1), &#39;)&#39;) AS msg FROM OCCUPATIONS ORDER BY Name ) r1 ) UNION ALL ( SELECT msg , 2 AS filter1 , ROW_NUMBER() OVER(ORDER BY num ASC, msg) AS filter2 FROM ( SELECT COUNT(*) as num , CONCAT( &#39;There are a total of &#39; , COUNT(*) , &#39; &#39; , LOWER(Occupation) , &#39;s.&#39; ) AS msg FROM OCCUPATIONS GROUP BY Occupation ORDER BY num ASC, msg ) r2 )) retORDER BY filter1, filter2filter값을 추가해서 나중에 다시 정렬하는 방법을 사용하였습니다.하지만… 그냥 이렇게 출력해도 되는거였다;SELECT CONCAT(Name, &#39;(&#39;, SUBSTR(Occupation, 1, 1), &#39;)&#39;) AS msgFROM OCCUPATIONSORDER BY Name;SELECT CONCAT( &#39;There are a total of &#39; , COUNT(*) , &#39; &#39; , LOWER(Occupation) , &#39;s.&#39; ) AS msgFROM OCCUPATIONSGROUP BY OccupationORDER BY COUNT(*) ASC, msg;Weather Observation Station 20SELECT ROUND(LAT_N, 4)FROM ( SELECT LAT_N , ROW_NUMBER() OVER(ORDER BY LAT_N) AS num FROM STATION) retWHERE num = ( SELECT CEIL(COUNT(*) / 2) FROM STATION)Interviews길긴 하지만 별 내용은 없었다.SELECT cont.contest_id , cont.hacker_id , cont.name , SUM(submsum.total_submissions) AS total_submissins , SUM(submsum.total_accepted_submissions) AS total_accepted_submissions , SUM(viewsum.total_views) AS total_views , SUM(viewsum.total_unique_views) AS total_unique_viewsFROM Contests cont LEFT JOIN Colleges coll ON cont.contest_id=coll.contest_id LEFT JOIN Challenges chal ON coll.college_id=chal.college_id LEFT JOIN ( SELECT challenge_id , SUM(total_views) AS total_views , SUM(total_unique_views) AS total_unique_views FROM View_Stats GROUP BY challenge_id ) AS viewsum ON chal.challenge_id=viewsum.challenge_id LEFT JOIN ( SELECT challenge_id , SUM(total_submissions) AS total_submissions , SUM(total_accepted_submissions) AS total_accepted_submissions FROM Submission_Stats GROUP BY challenge_id ) AS submsum ON chal.challenge_id=submsum.challenge_idGROUP BY cont.contest_id, cont.hacker_id, cont.nameHAVING ( SUM(submsum.total_submissions) + SUM(submsum.total_accepted_submissions) + SUM(viewsum.total_views) + SUM(viewsum.total_unique_views) ) &amp;gt; 0ORDER BY cont.contest_id" }, { "title": "PostgreSQL + DBeaver 시작하기", "url": "/posts/postgresql_and_dbeaver/", "categories": "DB", "tags": "SQL, DB", "date": "2022-02-21 00:00:00 +0900", "snippet": "데이터 분석을 위한 SQL 레시피 실습환경을 설정한 과정을 정리하였습니다.PostgreSQL posgres Docker Image를 받아줍니다. docker pull postgres 이제 컨테이너를 만들어줍니다. docker run --name postgres-demo -e POSTGRES_PASSWORD=junyeop -p 5432:5432 -v /Users/junyeop/Documents/try_everything/SQL_Recipe_sample-code:/mnt -d postgres 5432포트를 연결하고 sql파일들이 있는 폴더를 마운트하여 postgres-demo라는 이름의 컨테이너를 만들었습니다. container로 접속해서 DB를 하나 만들어줍니다. docker exec -it postgres-demo bash psql -U postgres CREATE DATABASE demodb; DBeaver 여기서 알맞은 버전을 설치해줍니다. PostgreSQL로 연결해줍니다. Driver가 없으면 설치해줍니다. 생성한 DB정보와 비밀번호를 입력하고 연결해줍니다. 도커 컨테이너에서 sql파일을 이용해서 테이블을 만들어줍니다. 그러면 DBeaver에서도 테이블이 생성된 것을 확인할 수 있습니다. " }, { "title": "이것이 취업을 위한 코딩 테스트다 with 파이썬 - 최단 경로", "url": "/posts/python_for_coding_test_Shortest_path/", "categories": "Coding Test", "tags": "Algorithm", "date": "2022-01-30 00:00:00 +0900", "snippet": " 이것이 취업을 위한 코딩 테스트다 with 파이썬을 읽고 필요한 부분을 요약 정리하였습니다.Sortest path Dijkstra 방문하지 않은 노드 중에서 갖아 최단 거리가 짧은 노드를 선택하여 진행한다. 한 단계에 하나의 노드에 대한 최단 거리를 확정하면서 진행된다. 그리디 알고리즘. 각 단계에서 최단 거리가 짧은 노드를 선택할 때 최소 힙 라이브러인 heapq를 이용해 시간복잡도를 O(E log V)로 줄인다. import heapq # graph = edges # distance = 각 노드까지의 최단 거리 def dijkstra(start_node): q = [] heapq.heappush(q, (0, start_node)) distance[start_node] = 0 while q: dist, now = heapq.heappop(q) if distance[now] &amp;lt; dist: continue else: for i in graph[now]: cost = dist + i[1] if cost &amp;lt; distance[i[0]]: distance[i[0]] = cost heapq.heappush(q, (cost, i[0])) Floyd-Warchall 모든 지점에서 다른 모든 지점까지의 최단 경로를 모두 구해야 하는 경우에 사용한다. 다이나믹 프로그래밍. n개의 타겟 노드에 대해서 타겟 노드를 지나가는 최단 거리를 갱신(각각 시간복잡도가 O(N^2))한다. 시간복잡도가 O(N^3)이다. # 모든 k, a, b에 대해서 a -&amp;gt; b의 최단 경로와 a -&amp;gt; k -&amp;gt; b의 최단 거리를 비교 for k in range(1, n + 1): for a in range(1, n + 1): for b in range(1, n + 1): graph[a][b] = min(graph[a][b], graph[a][k] + graph[k][b]) 플로이드import sysinput = sys.stdin.readlinen = int(input())m = int(input())buses = [list(map(int, input().split())) for _ in range(m)]graph = [[1e9 for _ in range(n)] for _ in range(n)]for bus in buses: a, b, cost = bus graph[a - 1][b - 1] = min(cost, graph[a - 1][b - 1])for i in range(n): graph[i][i] = 0# Floyd-Warchall# a -&amp;gt; k -&amp;gt; bfor k in range(n): for a in range(n): for b in range(n): graph[a][b] = min(graph[a][b], graph[a][k] + graph[k][b])for a in range(n): for b in range(n): if graph[a][b] &amp;gt; 1e8: graph[a][b] = 0for row in graph: print(&quot; &quot;.join(map(str, row)))" }, { "title": "이것이 취업을 위한 코딩 테스트다 with 파이썬 - 그래프 알고리즘", "url": "/posts/python_for_coding_test_Graph_algorithms/", "categories": "Coding Test", "tags": "Algorithm", "date": "2022-01-30 00:00:00 +0900", "snippet": " 이것이 취업을 위한 코딩 테스트다 with 파이썬을 읽고 필요한 부분을 요약 정리하였습니다.Graph Algorithms Union-Find 경로 압축을 통해 시간 복잡도를 개선할 수 있다. def find_parent(parent, x): if parent[x] != x: parent[x] = find_parent(parent, parent[x]) return parent[x] def union_parent(parent, a, b): a = find_parent(parent, a) b = find_parent(parent, b) if a &amp;lt; b: parent[b] = a else: parent[a] = b 무방향 그래프내에서의 사이클을 판별할 때 사용할 수 있다. (방향 그래프에서의 사이클 여부는 DFS를 이용해서 판별할 수 있다.) 신장 트리, Spanning Tree 신장 트리란 하나의 그래프가 있을 때 모든 노드를 포함하면서 사이클이 존재하지 않는 부분 그래프를 의미한다. Kruskal Algorithm 최소 신장 트리 알고리즘(신장 트리 중에서 최소 비용으로 만들 수 있는 신장 트리를 찾는 알고리즘) 그리디 알고리즘으로 분류됨. 간선 데이터를 비용에 따라 오름차순으로 정렬 모든 간선에 대해 간선이 사이클을 발생시키지 않는다면 최소 신장 트리에 포함시킴 정렬에 가장 시간이 오래 걸리기 때문에 E개의 간선이 있을 때, 시간복잡도는 O(E log E)이다. Topology Algorithm 방향 그래프의 모든 노드를 방향성에 거스르지 않도록 순서대로 나열하는 것 예시: 선수과목을 고려한 학습 순서 결정 진입차수(indegree, 특정 노드로 들어오는 간선의 개수)가 0인 노드를 큐에 넣음 큐가 빌 때까지, 큐에서 원소를 꺼내 해당 노드에서 출발하는 간선을 그래프에서 제거 &amp;amp; 진입차수가 0이 된 노드를 큐에 넣음 from collections import deque indegree = 진입차수들 def topology_sort(): result = [] q = deque() for i in range(1, v + 1): if indegree[i] == 0: q.append(i) while q: now = q.popleft() result.append(now) for i in graph[now]: indegree[i] -= 1 if indegree[i] == 0: q.append(i) return result 행성 터널처음에는 모든 행성 사이의 거리를 체크하였고, n(n-1)/2 개를 비교했어야 했다. 이 경우 메모리 초과가 되었다.import sysinput = sys.stdin.readlinen = int(input())planets = [list(map(int, input().split())) for _ in range(n)]def find_parent(x): global parents if parents[x] != x: parents[x] = find_parent(parents[x]) return parents[x]def union_parent(a, b): global parents a = find_parent(a) b = find_parent(b) if a &amp;lt; b: parents[b] = a else: parents[a] = bdef get_dist(a, b): ax, ay, az = a bx, by, bz = b return min(abs(ax - bx), abs(ay - by), abs(az - bz))parents = [i for i in range(n)]distances = []for i in range(n): for j in range(i + 1, n): distances.append((i, j, get_dist(planets[i], planets[j])))distances.sort(key=lambda x: x[2])total_cost = 0for dist in distances: a, b, cost = dist if find_parent(a) != find_parent(b): total_cost += cost union_parent(a, b)print(total_cost)행성 사이의 거리는 x, y, z의 차이 중 가장 작은 것이다. 따라서 x, y, z 각각을 기준을 정렬을 했을 때 서로 이웃간의 거리들 이상으로 통로가 연결될 일을 없다.그래서 총 3*(n-1)개만 비교하면 된다.import sysinput = sys.stdin.readlinen = int(input())planets = [list(map(int, input().split())) + [idx] for idx in range(n)]def find_parent(x): global parents if parents[x] != x: parents[x] = find_parent(parents[x]) return parents[x]def union_parent(a, b): global parents a = find_parent(a) b = find_parent(b) if a &amp;lt; b: parents[b] = a else: parents[a] = bdef get_dist(a, b): ax, ay, az, aidx = a bx, by, bz, aidx = b return min(abs(ax - bx), abs(ay - by), abs(az - bz))parents = [i for i in range(n)]distances = []# x, y, z 별로 정렬해서, 각각 가장 작은 distance n - 1개를 distances에 추가# 총 3(n - 1)개의 distance만 확인하면 됨for idx in range(3): planets.sort(key=lambda x: x[idx]) for i in range(n - 1): distances.append((planets[i][3], planets[i + 1][3], get_dist(planets[i], planets[i + 1])))distances.sort(key=lambda x: x[2])total_cost = 0for dist in distances: a, b, cost = dist if find_parent(a) != find_parent(b): total_cost += cost union_parent(a, b)print(total_cost)최종 순위import sysfrom collections import dequeinput = sys.stdin.readlinedef topology_sort(): global n global indegrees result = [] dq = deque() for i in range(1, n + 1): if indegrees[i] == 0: dq.append(i) if len(dq) == 0: return result while dq: now = dq.popleft() result.append(now) for i in orders[now]: indegrees[i] -= 1 if indegrees[i] == 0: dq.append(i) if len(dq) &amp;gt; 1: return &quot;?&quot; return resultntests = int(input())for _ in range(ntests): n = int(input()) last_ranks = list(map(int, input().split())) m = int(input()) changes = dict() for _ in range(m): a, b = map(int, input().split()) if a in changes.keys(): changes[a].append(b) else: changes[a] = [b] if b in changes.keys(): changes[b].append(a) else: changes[b] = [a] orders = [[] for _ in range(n + 1)] for i in range(n - 1): for j in range(i + 1, n): if last_ranks[j] in changes.keys() and last_ranks[i] in changes[last_ranks[j]]: orders[last_ranks[j]].append(last_ranks[i]) else: orders[last_ranks[i]].append(last_ranks[j]) indegrees = [0 for _ in range(n + 1)] for row in orders: for j in row: indegrees[j] += 1 ret = topology_sort() if isinstance(ret, str): print(ret) elif len(ret) != n: print(&quot;IMPOSSIBLE&quot;) else: print(&quot; &quot;.join(map(str, ret)))" }, { "title": "이것이 취업을 위한 코딩 테스트다 with 파이썬 - 다이나믹 프로그래밍", "url": "/posts/python_for_coding_test_Dynamic_programming/", "categories": "Coding Test", "tags": "Algorithm", "date": "2022-01-30 00:00:00 +0900", "snippet": " 이것이 취업을 위한 코딩 테스트다 with 파이썬을 읽고 필요한 부분을 요약 정리하였습니다.Dynamic Programming한 번 계산된 문제는 다시 계산하지 않도록 하는 알고리즘정수삼각형import sysinput = sys.stdin.readlinen = int(input())triangle = [list(map(int, input().split())) for _ in range(n)]maxangle = triangle[:]for i in range(1, n): for j in range(0, i): if j - 1 &amp;lt; 0: maxangle[i][j] = maxangle[i - 1][j] + triangle[i][j] else: if i - 1 &amp;lt; j: maxangle[i][j] = maxangle[i - 1][j - 1] + triangle[i][j] else: maxangle[i][j] = max(maxangle[i - 1][j - 1], maxangle[i - 1][j]) + triangle[i][j]print(max(maxangle[-1]))퇴사import sysinput = sys.stdin.readlinen = int(input())counsels = list()max_pay = [0 for _ in range(n + 1)]for start in range(1, n + 1): duration, pay = map(int, input().split()) end = start + duration - 1 if end &amp;lt;= n: counsels.append((start, end, pay))# 끝나는 날짜 순으로 정렬counsels.sort(key=lambda x: x[1])for counsel in counsels: start, end, pay = counsel max_pay[start - 1] = max(max_pay[:start]) max_pay[end] = max(max_pay[end], max_pay[start - 1] + pay)print(max(max_pay))병사 배치하기import sysinput = sys.stdin.readlinen = int(input())soldiers = list(map(int, input().split()))LDS = [0 for _ in range(n)]for i in range(n): LDS[i] = max([LDS[v] for v in range(i + 1) if soldiers[v] &amp;gt; soldiers[i]], default=0) + 1print(n - max(LDS))" }, { "title": "이것이 취업을 위한 코딩 테스트다 with 파이썬 - 정렬", "url": "/posts/python_for_coding_test_Sorting/", "categories": "Coding Test", "tags": "Algorithm", "date": "2022-01-29 00:00:00 +0900", "snippet": " 이것이 취업을 위한 코딩 테스트다 with 파이썬을 읽고 필요한 부분을 요약 정리하였습니다.Sortingquick sort이미 데이터가 정렬되어 있는 경우에는 느리게 동작합니다. 아래 코드는 책에서 소개된 일반적인 quick sort보다는 비효율적이지만 코드가 간결한 방법입니다.def quick_sort(array): if len(array) &amp;lt;= 1: return array pivot = array[0] tail = array[1:] left_side = [x for x in tail if x &amp;lt;= pivot] right_side = [x for x in tail if x &amp;gt; pivot] return quick_sort(left_side) + [pivot] + quick_sort(right_side)count sort데이터 크기의 범위가 제한되어 있을 떄 사용가능하며 빠르게 동작합니다. 동일한 값을 가지는 데이터가 여러 개일 때 효과적입니다.sort()파이썬 내장 정렬 라이브러니는 최악의 경우에도 시간복잡도 O(N log N)을 보장해줍니다.국영수import sysinput = sys.stdin.readlinen = int(input())scores = [tuple() for _ in range(n)]for i in range(n): name, kor, eng, math = input().split() scores[i] = (str(name), int(kor), int(eng), int(math))scores.sort(key=lambda x: (-x[1], x[2], -x[3], x[0]))for v in scores: print(v[0])안테나import sysinput = sys.stdin.readlinen = int(input())houses = sorted(list(map(int, input().split())))print(houses[(len(houses) - 1) // 2])실패율def solution(N, stages): stages.sort(reverse=True) answer = [] n_users = len(stages) cur_num = [0 for _ in range(N + 2)] try_num = [0 for _ in range(N + 2)] fail_rate = [[0, i] for i in range(N + 2)] for i, s in enumerate(stages): cur_num[s] += 1 try_num[s] = i + 1 for i in range(N, 0, -1): if try_num[i] == 0: try_num[i] = try_num[i + 1] for i in range(N + 1): if try_num[i] != 0: fail_rate[i][0] = cur_num[i] / try_num[i] return [v[1] for v in sorted(fail_rate[1:N + 1], key=lambda x: (-x[0], x[1]))]카드 정렬하기import sysinput = sys.stdin.readlineimport heapqn = int(input())cards = []for _ in range(n): heapq.heappush(cards, int(input()))count = 0while len(cards) &amp;gt;= 2: a = heapq.heappop(cards) b = heapq.heappop(cards) count += a + b heapq.heappush(cards, a + b)print(count)" }, { "title": "이것이 취업을 위한 코딩 테스트다 with 파이썬 - DFS, BFS", "url": "/posts/python_for_coding_test_DFS_BFS/", "categories": "Coding Test", "tags": "Algorithm", "date": "2022-01-29 00:00:00 +0900", "snippet": " 이것이 취업을 위한 코딩 테스트다 with 파이썬을 읽고 필요한 부분을 요약 정리하였습니다.DFS, BFS특정 거리의 도시 찾기import sysinput = sys.stdin.readlinen_cities, n_roads, target_distance, start_city = map(int, input().split())roads = [[] for _ in range(n_cities + 1)]distances = [1e9 for _ in range(n_cities + 1)]for _ in range(n_roads): a, b = map(int, input().split()) roads[a].append(b)from collections import dequedef bfs(roads, distances, start_city): dq = deque([start_city]) while dq: now_city = dq.popleft() for next_city in roads[now_city]: dist = distances[now_city] + 1 if dist &amp;lt; distances[next_city]: distances[next_city] = dist dq.append(next_city) return distancesdistances[start_city] = 0final_distances = dfs(roads, distances, start_city)ret = sorted([i for i in range(n_cities + 1) if final_distances[i] == target_distance])if len(ret) == 0: print(-1)else: for r in ret: print(r)연구소import sysinput = sys.stdin.readlinefrom itertools import combinationsfrom collections import dequefrom copy import deepcopyn, m = map(int, input().split())lab = [list(map(int, input().split())) for _ in range(n)]# n, m이 8이하이므로 lab에서 3개를 선택하는 경우의 수는 C(64, 3) = 41664이고# 각각의 경우에 안전 영역의 크기를 구하는 시간복잡도는 O(N^2)이므로 전수조사를 해도 된다.def bfs(lab, viruses): dq = deque(viruses) while dq: x, y = dq.popleft() for dx, dy in zip([-1, 1, 0, 0], [0, 0, -1, 1]): if 0 &amp;lt;= x + dx &amp;lt; n and 0 &amp;lt;= y + dy &amp;lt; m: if lab[x + dx][y + dy] == 0: lab[x + dx][y + dy] = 2 dq.append((x + dx, y + dy)) return labdef get_area(lab): count = 0 for i in range(n): for j in range(m): if lab[i][j] == 0: count += 1 return count# 벽을 세울 후보지 &amp;amp; 바이러스 찾기wall_candidates = list()viruses = list()for i in range(n): for j in range(m): if lab[i][j] == 0: wall_candidates.append((i, j)) if lab[i][j] == 2: viruses.append((i, j))max_area = 0for walls in combinations(wall_candidates, 3): lab_copy = deepcopy(lab) for wall in walls: i, j = wall lab_copy[i][j] = 1 lab_copy = bfs(lab_copy, viruses) max_area = max(max_area, get_area(lab_copy))print(max_area)경쟁적 전염import sysinput = sys.stdin.readlinefrom collections import dequen, k = map(int, input().split())lab = [list(map(int, input().split())) for _ in range(n)]s, target_x, target_y = map(int, input().split())# 바이러스 위치 찾기viruses = list()for i in range(n): for j in range(n): if lab[i][j] != 0: viruses.append((lab[i][j], i, j, 0))viruses.sort()dq = deque(viruses)while dq: virus_num, x, y, time = dq.popleft() if time &amp;gt;= s: break for dx, dy in ((-1, 0), (1, 0), (0, -1), (0, 1)): # 상하좌우 if 0 &amp;lt;= x + dx &amp;lt; n and 0 &amp;lt;= y + dy &amp;lt; n: if lab[x + dx][y + dy] == 0: lab[x + dx][y + dy] = virus_num dq.append((virus_num, x + dx, y + dy, time + 1))print(lab[target_x - 1][target_y - 1])괄호 변환def split_uv(w): count_left = 0 count_right = 0 for i in range(len(w)): if w[i] == &quot;(&quot;: count_left += 1 elif w[i] == &quot;)&quot;: count_right += 1 if count_left == count_right: return w[:i + 1], w[i + 1:] def is_correct(u): count = 0 for v in u: if v == &quot;(&quot;: count += 1 elif v == &quot;)&quot;: count -= 1 if count &amp;lt; 0: return False return Truedef solution(w): if len(w) == 0: return w u, v = split_uv(w) if is_correct(u): return u + solution(v) else: reversed_u = &quot;&quot; for ss in u[1:-1]: if ss == &quot;(&quot;: reversed_u += &quot;)&quot; else: reversed_u += &quot;(&quot; return &quot;(&quot; + solution(v) + &quot;)&quot; + reversed_u연산자 끼워 넣기set을 이용해서 중복을 제거해주지 않으면 시간초과가 발생한다. 백준기준 596ms가 걸렸다.import sysinput = sys.stdin.readline# 10! = 3628800이고 시간 제한은 2초이므로 전수조사로 진행from itertools import permutationsn = int(input())nums = list(map(int, input().split()))n_plus, n_minus, n_multiply, n_divide = map(int, input().split())operators = ( [&quot;+&quot;] * n_plus + [&quot;-&quot;] * n_minus + [&quot;*&quot;] * n_multiply + [&quot;/&quot;] * n_divide)def calculate(nums, ops): ret = nums[0] for i in range(len(ops)): if ops[i] == &quot;+&quot;: ret += nums[i + 1] elif ops[i] == &quot;-&quot;: ret -= nums[i + 1] elif ops[i] == &quot;*&quot;: ret *= nums[i + 1] elif ops[i] == &quot;/&quot;: if ret &amp;lt; 0: ret = -((-ret) // nums[i + 1]) else: ret = ret // nums[i + 1] return retmax_value = int(-1e9)min_value = int(1e9)for ops in set(permutations(operators, len(operators))): new_value = calculate(nums, list(ops)) min_value = min(min_value, new_value) max_value = max(max_value, new_value)print(max_value)print(min_value)dfs를 사용하면 중복되는 계산을 줄일 수 있고 시간도 더 단축된다.(백준기준 104ms)import sysinput = sys.stdin.readlinen = int(input())nums = list(map(int, input().split()))n_plus, n_minus, n_multiply, n_divide = map(int, input().split())def dfs(depth, new_value): global min_value, max_value global n_plus, n_minus, n_multiply, n_divide if depth == n: min_value = min(min_value, new_value) max_value = max(max_value, new_value) else: if n_plus &amp;gt; 0: n_plus -= 1 dfs(depth + 1, new_value + nums[depth]) n_plus += 1 if n_minus &amp;gt; 0: n_minus -= 1 dfs(depth + 1, new_value - nums[depth]) n_minus += 1 if n_multiply &amp;gt; 0: n_multiply -= 1 dfs(depth + 1, new_value * nums[depth]) n_multiply += 1 if n_divide &amp;gt; 0 : n_divide -= 1 if new_value &amp;lt; 0: dfs(depth + 1, -((-new_value) // nums[depth])) else: dfs(depth + 1, new_value // nums[depth]) n_divide += 1max_value = int(-1e9)min_value = int(1e9)dfs(1, nums[0])print(max_value)print(min_value)감시 피하기import sysinput = sys.stdin.readlinefrom itertools import permutationsn = int(input())field = [list(map(str, input().split())) for _ in range(n)]# T의 위치 &amp;amp; 빈칸 위치 구하기ts = list()candidates = list()for i in range(n): for j in range(n): if field[i][j] == &quot;T&quot;: ts.append((i, j)) if field[i][j] == &quot;X&quot;: candidates.append((i, j))def check(): global field, ts for x, y in ts: for new_x in range(x + 1, n, 1): if field[new_x][y] == &quot;O&quot;: break elif field[new_x][y] == &quot;S&quot;: return False for new_x in range(x - 1, -1, -1): if field[new_x][y] == &quot;O&quot;: break elif field[new_x][y] == &quot;S&quot;: return False for new_y in range(y + 1, n, 1): if field[x][new_y] == &quot;O&quot;: break elif field[x][new_y] == &quot;S&quot;: return False for new_y in range(y - 1, -1, -1): if field[x][new_y] == &quot;O&quot;: break elif field[x][new_y] == &quot;S&quot;: return False return Truedef try_candidates(): for candidate in permutations(candidates, 3): for i, j in candidate: field[i][j] = &quot;O&quot; if check(): print(&quot;YES&quot;) return for i, j in candidate: field[i][j] = &quot;X&quot; print(&quot;NO&quot;) returntry_candidates()인구 이동import sysfrom collections import dequeinput = sys.stdin.readlinen, l, r = map(int, input().split())a = [list(map(int, input().split())) for _ in range(n)]def move(x, y): visited[x][y] = True united = [(x, y)] united_sum = a[x][y] dq = deque([(x, y)]) while dq: x, y = dq.popleft() for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)): nx = x + dx ny = y + dy if ( 0 &amp;lt;= nx &amp;lt; n and 0 &amp;lt;= ny &amp;lt; n and not visited[nx][ny] and l &amp;lt;= abs(a[x][y] - a[nx][ny]) &amp;lt;= r ): visited[nx][ny] = True united_sum += a[nx][ny] united.append((nx, ny)) dq.append((nx, ny)) for i, j in united: a[i][j] = united_sum // len(united) return len(united) - 1time = 0while True: is_moved = 0 visited = [[False for _ in range(n)] for _ in range(n)] for x in range(n): for y in range(n): if not visited[x][y]: is_moved += move(x, y) if is_moved == 0: break time += 1print(time)블록 이동하기지나간 곳의 좌표를 string으로 변환한 후 set에 저장한 후, 다시 지나가지 않도록 체크했다.(이 부분을 list로 했을 때보다 실행시간이 많이 줄어들었다.)from calendar import cfrom collections import dequefrom tabnanny import checkdef get_routes(a, b, board, N): for dx, dy in [(1, 0), (-1, 0), (0, 1), (0, -1)]: na = (a[0] + dx, a[1] + dy) nb = (b[0] + dx, b[1] + dy) if ( 1 &amp;lt;= na[0] &amp;lt;= N and 1 &amp;lt;= na[1] &amp;lt;= N and 1 &amp;lt;= nb[0] &amp;lt;= N and 1 &amp;lt;= nb[1] &amp;lt;= N and board[na[0]][na[1]] == 0 and board[nb[0]][nb[1]] == 0 ): yield (na, nb) if a[0] == b[0]: # 로봇이 가로로 있으면 if a[1] &amp;gt; b[1]: # a가 b 왼쪽에 있도록 a, b = b, a # 위에 공간이 있으면 if ( 1 &amp;lt;= a[0] - 1 &amp;lt;= N and board[a[0] - 1][a[1]] == 0 and board[b[0] - 1][b[1]] == 0 ): na = a nb = (a[0] - 1, a[1]) yield (na, nb) na = (b[0] - 1, b[1]) nb = b yield (na, nb) # 아래에 공간이 있으면 if ( 1 &amp;lt;= a[0] + 1 &amp;lt;= N and board[a[0] + 1][a[1]] == 0 and board[b[0] + 1][b[1]] == 0 ): na = a nb = (a[0] + 1, a[1]) yield (na, nb) na = (b[0] + 1, b[1]) nb = b yield (na, nb) else: # 로봇이 세로로 있으면 if a[0] &amp;gt; b[0]: # a가 b 위쪽에 있도록 a, b = b, a # 왼쪽에 공간이 있으면 if ( 1 &amp;lt;= a[1] - 1 &amp;lt;= N and board[a[0]][a[1] - 1] == 0 and board[b[0]][b[1] - 1] == 0 ): na = a nb = (a[0], a[1] - 1) yield (na, nb) na = (b[0], b[1] - 1) nb = b yield (na, nb) # 오른쪽에 공간이 있으면 if ( 1 &amp;lt;= a[1] + 1 &amp;lt;= N and board[a[0]][a[1] + 1] == 0 and board[b[0]][b[1] + 1] == 0 ): na = a nb = (a[0], a[1] + 1) yield (na, nb) na = (b[0], b[1] + 1) nb = b yield (na, nb)def solution(board): N = len(board) new_board = [[0 for _ in range(N + 1)]] for row in board: new_board.append([0] + row) min_time = 1e9 checked = set() a, b = (1, 1), (1, 2) checked.add(str((a, b))) checked.add(str((b, a))) dq = deque([((1, 1), (1, 2), 0)]) while dq: a, b, time = dq.popleft() if time + 1 &amp;gt;= min_time: continue for na, nb in get_routes(a, b, new_board, N): if str((na, nb)) not in checked: checked.add(str((na, nb))) checked.add(str((nb, na))) if na == (N, N) or nb == (N, N): min_time = min(min_time, time + 1) dq.append((na, nb, time + 1)) return min_time" }, { "title": "이것이 취업을 위한 코딩 테스트다 with 파이썬 - 이진 탐색", "url": "/posts/python_for_coding_test_Binary_search/", "categories": "Coding Test", "tags": "Algorithm", "date": "2022-01-29 00:00:00 +0900", "snippet": " 이것이 취업을 위한 코딩 테스트다 with 파이썬을 읽고 필요한 부분을 요약 정리하였습니다.Binary Search정렬된 배열에서 사용할 수 있습니다.def binary_search(array, target, start, end): while start &amp;lt;= end: mid = (start + end) // 2 if array[mid] == target: return mid elif array[mid] &amp;gt; target: end = mid - 1 else: start = mid + 1 returnBinary Search Tree 왼쪽 자식 노드 &amp;lt; 부모 노드 &amp;lt; 오른쪽 자식 노드공유기 설치" }, { "title": "Python - numpy issue 등록해보기", "url": "/posts/python_numpy_issue/", "categories": "Python", "tags": "Python", "date": "2022-01-26 00:00:00 +0900", "snippet": "numpy를 사용하던 중 이상한 부분을 확인하여 GitHub issue 등록을 하였습니다.문제 발견weights에 np.nan이 포함되어 있을 경우 mask된 위치라도 결과가 np.nan으로 나왔습니다.np.ma.average( np.ma.array([1., 2., 3., 4.], mask=[False, False, True, True]), weights=np.array([1, 1, 1, np.nan]), returned=True)-&amp;gt;(nan, nan) docs에서 avg값을 sum(weights)로 나눠서 계산하는 부분 때문에 문제가 생길까 싶었지만, masked된 값은 계산에 사용되지 않는다고해서 정확한 문제가 무엇인지 알 수 없었습니다. weights 부분에서는 “The importance that each element has in the computation of the average.”로 weights 부분은 계산에 사용된다는 설명이 있었습니다. 그래서 sorucecode를 찾아보았습니다. 위의 problem 상황에서 sourcecode를 간단히하면 다음과 같이 계산됩니다. np.ma.average(a, weights) -&amp;gt; wgt = np.asanyarray(weights) wgt = wgt*(~a.mask) scl = wgt.sum() avg = np.multiply(a, wgt).sum() / scl 여기서 wgt*(~a.mask) 를 계산할 때 wgt에 있는 np.nan의 경우 사라지지 않고 그대로 유지되어 scl을 계산하게되고, 따라서 scl이 np.nan이 됩니다. Issue 등록 2021-11-15 관련된 설명을 찾기가 힘들었고, 이 문제에 대해 GitHub에 Issue(#20375)를 등록해보았습니다. 2021-12-03 아무도 답변을 달아주지 않아서 잘못올렸나 싶었지만, 몇 주 뒤에 한 분이 문제를 확인하고 PR(#20505)까지 해주셨습니다. PR 코드에 테스트 케이스도 추가되어있는 것을 보고 이렇게 하는 거구나라는 생각이 들었고, 저도 PR을 해보고 싶었습니다. 2022-12-09 며칠 뒤에 몇 분이 해당 PR을 검토해주셨습니다. 그 과정에서 asarray와 asanyarray에 대해 말이 오갔었고 해당 내용을 개인적으로 찾아보았습니다. (Python - numpy asarray 비교) 2022-12-24 머지되었습니다! 실제 사용하는 numpy에도 반영될때까지 지켜볼 예정입니다. 작은 경험이었지만 오픈소스가 이렇게 발전되고 있구나라는 생각을 하게된 좋은 경험이었습니다. 다음에는 PR도 생성해보고 싶네요." }, { "title": "Python - numpy asarray 비교", "url": "/posts/python_numpy_asarray_asanyarray/", "categories": "Python", "tags": "Python", "date": "2022-01-26 00:00:00 +0900", "snippet": "Array creation routines 이 질문을 이해하기 위해서 np.ma.asarray와 np.asanyarray의 차이를 찾아보았습니다 MaskedArray Class는 missing data를 다루기 위한 ndarray의 subclass입니다. MaskedArray는 일반적인 np.ndarray로 된 data 부분과 해당 data의 boolean mask부분으로 되어있습니다. np.asarray : Convert the input to an array. : No copy is performed if the input is already an ndarray with matching dtype and order. : If a is a subclass of ndarray, a base class ndarray is returned. np.asanyarray : Convert the input to an ndarray, but pass ndarray subclasses through. : If a is an ndarray or a subclass of ndarray, it is returned as-is and no copy is performed. np.ma.asarray : Convert the input to a masked array of the given data-type. : No copy is performed if the input is already an ndarray. If a is a subclass of MaskedArray, a base class MaskedArray is returned. np.ma.asanyarray : Convert the input to a masked array, conserving subclasses. : If a is a subclass of MaskedArray, its class is conserved. No copy is performed if the input is already an ndarray. → code를 보면 subok=True condition에서 asarry와 차이가 있는 것을 확인할 수 있습니다. ExampleMaskedArray를 input으로 주었을 때, np.asarray는 ndarray를 return하고, np.asanyarray, np.ma.asarry, np.ma.asanyarray는 MaskedArray를 return하는 것을 확인할 수 있습니다.asanyarray의 경우 input이 MaskedArray인 경우 아래와 같이 input을 그대로 반환하기에 is 비교시 True값을 얻을 수 있었습니다.def asanyarray(a, dtype=None): if isinstance(a, MaskedArray) and (dtype is None or dtype == a.dtype): return a return masked_array(a, dtype=dtype, copy=False, keep_mask=True, subok=True) 참고자료 https://numpy.org/doc/stable/reference/routines.array-creation.html#routines-array-creation " }, { "title": "백준 단계별 - 브루트 포스 알고리즘", "url": "/posts/BOJ_brute_force/", "categories": "Coding Test", "tags": "Algorithm", "date": "2022-01-21 00:00:00 +0900", "snippet": "문제풀이블랙잭import sysinput = sys.stdin.readlinefrom itertools import combinationsn, m = map(int, input().split())cards = list(map(int, input().split()))nearest_max = 0for subset in combinations(cards, 3): # 모든 경우의 수 탐색 new_sum = sum(subset) if new_sum &amp;lt;= m and new_sum &amp;gt; nearest_max: nearest_max = new_sumprint(nearest_max)분해합import sysinput = sys.stdin.readlinen = int(input())def find_generator(n): # n이 1000000이하 이므로 전수조사 for m in range(n): if (m + sum(map(int, str(m)))) == n: return m return 0print(find_generator(n))전수조사 범위를 조금 더 제한시키면 실행시간이 더 줄어든다. (백준 기준 1100ms에서 72ms로 줄어듬)import sysinput = sys.stdin.readlinen = int(input())def find_generator(n): # n이 1000000이하 이므로 전수조사 for m in range(max(1, n - len(str(n))*9), n): if (m + sum(map(int, str(m)))) == n: return m return 0print(find_generator(n))덩치import sysinput = sys.stdin.readlinen = int(input())dungchis = [tuple(map(int, input().split())) for _ in range(n)]# 전수조사를 할 경우 시간복잡도가 O(n^2)이고 n의 최대값이 50이므로 전수조사를 하였다.for dch_target in dungchis: rank = 0 for dch in dungchis: if dch_target[0] &amp;lt; dch[0] and dch_target[1] &amp;lt; dch[1]: rank += 1 print(rank + 1, end=&quot; &quot;)체스판 다시 칠하기import sysinput = sys.stdin.readlinen, m = map(int, input().split())board = [input().strip() for _ in range(n)]# 전수조사하였을 때 시간복잡도는 O(n^4), n은 50이하이고 50^4 = 6250000이다. 그래서 전수조사를 진행했다.piece_white = &quot;WBWBWBWB&quot;piece_black = &quot;BWBWBWBW&quot;board_white = ([piece_white] + [piece_black]) * 4board_black = ([piece_black] + [piece_white]) * 4brush_min = 8*8for x_start in range(n - 8 + 1): for y_start in range(m - 8 + 1): brush_white = 0 brush_black = 0 for dx in range(8): for dy in range(8): if board[x_start + dx][y_start + dy] != board_white[dx][dy]: brush_white += 1 if board[x_start + dx][y_start + dy] != board_black[dx][dy]: brush_black += 1 brush_min = min(brush_min, brush_white, brush_black)print(brush_min)영화감독 숌시간을 조금 걸리지만(백준 기준 1352ms), 문제를 푸는 시간이 짧아서 좋은 것 같다.import sysinput = sys.stdin.readlinenth = int(input())# 6660000은 10000번째로 작은 종말의 숫자보다 크기 때문에 최대 6660000까지만 전수조사를 하면 문제를 풀 수 있다.def is_apocalypse(num): if str(num).find(&quot;666&quot;) &amp;gt;= 0: return True else: return Falsenum = 0count = 0while True: if is_apocalypse(num): count += 1 if count == nth: break num += 1print(num)" }, { "title": "이것이 취업을 위한 코딩 테스트다 with 파이썬 - 구현", "url": "/posts/python_for_coding_test_implement/", "categories": "Coding Test", "tags": "Algorithm", "date": "2022-01-19 00:00:00 +0900", "snippet": " 이것이 취업을 위한 코딩 테스트다 with 파이썬을 읽고 필요한 부분을 요약 정리하였습니다.구현 완전탐색: 모든 경우의 수를 다 계산하는 방법 시뮬레이션: 문제에서 제시한 내용을 한 단계씩 차례대로 직접 수행상하좌우import sysinput = sys.stdin.readlinen = int(input())routes = list(input().strip().split())mapping = { &quot;L&quot;: (0, -1), &quot;R&quot;: (0, 1), &quot;U&quot;: (-1, 0), &quot;D&quot;: (1, 0),}x, y = 1, 1for route in routes: dx, dy = mapping[route] if 1 &amp;lt;= x + dx &amp;lt;= n and 1 &amp;lt;= y + dy &amp;lt;= n: x += dx y += dyprint(f&quot;{x} {y}&quot;)시각import sysinput = sys.stdin.readlinen = int(input())count = 0for hour in range(0, n + 1): if &quot;3&quot; in str(hour): count += (6 * 10 * 6 * 10) else: # 전체 경우의 수 - 3을 포함하지 않는 경우의 수 count += (6 * 10 * 6 * 10) - (5 * 9 * 5 * 9)print(count)왕실의 나이트import sysinput = sys.stdin.readlinechecklist = [ (2, 1), (2, -1), (-2, 1), (-2, -1), (1, 2), (-1, 2), (1, -2), (-1, -2),]location = input().strip()x = ord(location[0]) - 96y = int(location[1])count = 0for check in checklist: dx, dy = check if 1 &amp;lt;= x + dx &amp;lt;= 8 and 1 &amp;lt;= y + dy &amp;lt;= 8: count += 1print(count)게임 개발문제의 조건을 이해하기 조금 어려웠다.import sysinput = sys.stdin.readlinen, m = map(int, input().split())x, y, cur_direction = map(int, input().split())field = [list(map(int, input().split())) for _ in range(n)]directions = [(-1, 0), (0, 1), (1, 0), (0, -1)]field[x][y] = 2count = 1while True: print(x, y, cur_direction) dx, dy = directions[(cur_direction - 1) % 4] sub_count = 0 for direction in directions: xx, yy = direction if field[x + xx][y + yy] != 0: sub_count += 1 if sub_count == 4: if 0 &amp;lt;= x - dx &amp;lt; n and 0 &amp;lt;= y - dy &amp;lt; m and field[x - dy][y - dy] == 2: x -= dx y -= dy continue else: break if 0 &amp;lt;= x + dx &amp;lt; n and 0 &amp;lt;= y + dy &amp;lt; m: if field[x + dx][y + dy] == 0: cur_direction = (cur_direction - 1) % 4 field[x + dx][y + dy] = 2 count += 1 x += dx y += dy else: cur_direction = (cur_direction - 1) % 4print(count)럭키 스트레이트import sysinput = sys.stdin.readlinepoints = list(map(int, input().strip()))if sum(points[:len(points)//2]) == sum(points[len(points)//2:]): print(&quot;LUCKY&quot;)else: print(&quot;READY&quot;)문자열 재정렬import sysinput = sys.stdin.readlines = input().strip()s_with_str = []count = 0for ch in s: if ch.isdigit(): count += int(ch) else: s_with_str.append(ch)print(f&quot;{&#39;&#39;.join(sorted(s_with_str))}{count}&quot;)문자열 압축def solution(s): compressed_len_min = 10e9 for cut_length in range(1, len(s) // 2 + 2): compressed_len = 0 prev_ch = &quot;&quot; count = 1 for i in range(0, len(s), cut_length): ch = s[i:i+cut_length] if ch == prev_ch: count += 1 else: if count &amp;gt; 1: # 겹치는 부분이 있으면 숫자길이 추가 compressed_len += len(str(count)) count = 1 compressed_len += len(prev_ch) prev_ch = ch if count &amp;gt; 1: compressed_len += len(str(count)) compressed_len += len(prev_ch) compressed_len_min = min(compressed_len_min, compressed_len) return compressed_len_min이렇게 zip을 이용하는 방법도 코드를 이해하기 쉽다는 점에서 괜찮아보인다.def compress(s, cut_length): words = [s[i:i+cut_length] for i in range(0, len(s), cut_length)] res = [] cur_word = words[0] count = 1 for a, b in zip(words, words[1:] + [&#39;&#39;]): if a == b: count += 1 else: res.append([cur_word, count]) cur_word = b count = 1 return sum(len(word) + (len(str(cnt)) if cnt &amp;gt; 1 else 0) for word, cnt in res)def solution(s): return min([ min( compress(s, cut_length) for cut_length in list(range(1, len(s) // 2 + 2)) ), len(s) ])자물쇠와 열쇠key를 lock의 전체 위치에 대어보면서 겹치는 부분의 숫자를 더해서 1이 아닌 숫자가 있는지 확인하면 됩니다.key를 회전하는데 쓴 코드인 key = list(zip(*key[::-1]))를 잘 기억해둡시다!def check(key, lock, dx, dy): m = len(key) n = len(lock) for i in range(n): for j in range(n): key_i, key_j = i + dx, j + dy if 0 &amp;lt;= key_i &amp;lt; m and 0 &amp;lt;= key_j &amp;lt; m: if (lock[i][j] + key[key_i][key_j]) != 1: return False else: if lock[i][j] != 1: return False return Truedef solution(key, lock): m = len(key) n = len(lock) for _ in range(4): for dx in range(-n + 1, m): for dy in range(-n + 1, m): if check(key, lock, dx, dy): return True key = list(zip(*key[::-1])) # key 돌리기 return False뱀import sysinput = sys.stdin.readlinefrom collections import dequen = int(input())k = int(input())apples = {tuple(map(int, input().split())) for _ in range(k)}l = int(input())dq_changes = deque([tuple(input().split()) for _ in range(l)])directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]cur_direction = 0x, y = 1, 1cur_time = 0dq_snake = deque([(x, y)])next_change = dq_changes.popleft()while True: dx, dy = directions[cur_direction] if ( 1 &amp;lt;= x + dx &amp;lt;= n and 1 &amp;lt;= y + dy &amp;lt;= n and (x + dx, y + dy) not in dq_snake ): # 보드를 벗어나지 않고 자신과 겹치지 않으면 전진 if (x + dx, y + dy) in apples: apples.discard((x + dx, y + dy)) dq_snake.append((x + dx, y + dy)) else: dq_snake.append((x + dx, y + dy)) dq_snake.popleft() x, y = x + dx, y + dy cur_time += 1 else: break if cur_time == int(next_change[0]): # 방향 전환 if next_change[1] == &quot;L&quot;: cur_direction = (cur_direction - 1) % 4 else: cur_direction = (cur_direction + 1) % 4 if len(dq_changes) &amp;gt; 0: next_change = dq_changes.popleft()print(cur_time + 1)기둥과 보 설치중간에 하나를 잘못적어서 찾아내는데 시간이 많이 걸렸다. 문제를 상상하면서 조건문을 많이 설정하니 한 번에 풀지 못했을 때, 해결이 어려운 것 같다.조건문에 주석을 계속 달면서 풀니까 나중에 보기가 쉬웠다. 주석달면서 풀기!def check(x, y, a, n): global ff if a == 0: if not (0 &amp;lt;= x &amp;lt;= n and 0 &amp;lt;= y + 1 &amp;lt;= n): return False if {1, 2, 3}.intersection(ff[x][y]): return True else: return False elif a == 1: if not (0 &amp;lt;= x + 1 &amp;lt;= n and 0 &amp;lt;= y &amp;lt;= n): return False if ( {1}.intersection(ff[x][y]) or {1}.intersection(ff[x + 1][y]) or ( {2}.intersection(ff[x + 1][y]) and {3}.intersection(ff[x][y]) ) ): return True else: return False def insert(x, y, a, n): global ff if check(x, y, a, n): if a == 0: # 기둥 ff[x][y].add(0) ff[x][y + 1].add(1) elif a == 1: # 보 ff[x][y].add(2) ff[x + 1][y].add(3)def delete(x, y, a, n): global ff if a == 0: # 기둥 ff[x][y].remove(0) ff[x][y + 1].remove(1) if ( 0 &amp;lt;= y + 1 &amp;lt;= n and {0}.intersection(ff[x][y + 1]) and not check(x,y+1,0,n) ): # 위에 기둥이 있다면 ff[x][y].add(0) ff[x][y + 1].add(1) return if ( {2}.intersection(ff[x][y + 1]) and not check(x,y + 1,1,n) ): # 오른쪽 위에 보가 있다면 ff[x][y].add(0) ff[x][y + 1].add(1) return if ( {3}.intersection(ff[x][y + 1]) and not check(x-1,y + 1,1,n) ): # 왼쪽 위에 보가 있다면 ff[x][y].add(0) ff[x][y + 1].add(1) return if a == 1: # 보 ff[x][y].remove(2) ff[x + 1][y].remove(3) if ( {0}.intersection(ff[x][y]) and not check(x,y,0,n) ): # 위에 기둥이 있다면 ff[x][y].add(2) ff[x + 1][y].add(3) return if ( {0}.intersection(ff[x + 1][y]) and not check(x + 1,y,0,n) ): # 오른쪽 위에 기둥이 있다면 ff[x][y].add(2) ff[x + 1][y].add(3) return if ( {3}.intersection(ff[x][y]) and not check(x-1,y,1,n) ): # 왼쪽에 보가 있다면 ff[x][y].add(2) ff[x + 1][y].add(3) return if ( {2}.intersection(ff[x + 1][y]) and not check(x+1,y,1,n) ): # 오른쪽에 보가 있다면 ff[x][y].add(2) ff[x + 1][y].add(3) return def solution(n, build_frame): # 0: 기둥 시작 # 1: 기둥 끝 # 2: 보 시작 # 3: 보 끝 global ff ff = [[set() for _ in range(n + 1)] for _ in range(n + 1)] for x in range(n + 1): # 바닥은 보의 끝부분으로 설정 ff[x][0].add(1) for bf in build_frame: x, y, a, b = bf if b == 0: # 삭제 delete(x, y, a, n) elif b == 1: # 설치 insert(x, y, a, n) ret = list() for x in range(n + 1): for y in range(n + 1): if {0}.intersection(ff[x][y]): ret.append([x,y,0]) if {2}.intersection(ff[x][y]): ret.append([x,y,1]) ret.sort(key=lambda x: (x[0], x[1], x[2])) return ret책에서 제시한 조금 더 짧은 코드를 따라해보았다. 책의 코드는 작업이 이루어질 때마다 전체상황을 판단하도록 되어있었다. 위의 코드와 비교했을 때 실행시간은 많게는 200배 가까이 차이가 발생하였다. 하지만 이 코드도 문제는 통과하였다.더 간단하고 빠른 구조와 풀이를 찾기보다 시간복잡도와 제한시간을 고려해 최대한 간결한 코드를 작성하는 편이 문제를 더 빨리 풀기에는 좋은 것 같다. 문제 풀기 전에 허용가능한 시간복잡도 생각해보기!def possible(answer): for x, y, stuff in answer: if stuff == 0: # 기둥 if ( y == 0 # 바닥이거나 or [x - 1, y, 1] in answer # 보의 오른쪽 끝이거나 or [x, y, 1] in answer # 보의 왼쪽 끝이거나 or [x, y - 1, 0] in answer # 기둥의 위거나 ): continue return False elif stuff == 1: # 보 if ( [x, y - 1, 0] in answer # 왼쪽 밑에 기둥이 있거나 or [x + 1, y - 1, 0] in answer # 오른쪽 밑에 기둥이 있거나 or ( # 왼쪽 오른쪽 모두에 보가 있거나 [x - 1, y, 1] in answer and [x + 1, y, 1] in answer ) ): continue return False return Truedef solution(n, build_frame): answer = [] for frame in build_frame: x, y, stuff, operate = frame if operate == 0: # 삭제 answer.remove([x, y, stuff]) if not possible(answer): answer.append([x, y, stuff]) if operate == 1: # 설치 answer.append([x, y, stuff]) if not possible(answer): answer.remove([x, y, stuff]) return sorted(answer)치킨 배달combinations(list(range(13)), 6) * 100 * 13 = 1716 * 100 * 13 = 2230800 으로 전수조사를 해도 되겠다고 생각해서 전수조사했다.import sysinput = sys.stdin.readlinefrom itertools import combinationsn, m = map(int, input().split())city = [list(map(int, input().split())) for _ in range(n)]def get_dist(house, chicken): return abs(house[0] - chicken[0]) + abs(house[1] - chicken[1])houses = list()chikens = list()# 집과 치킨집 리스트 구하기for row in range(n): for col in range(n): if city[row][col] == 1: houses.append((row, col)) elif city[row][col] == 2: chikens.append((row, col))# 집에서 치킨집까지 거리를 모두 구하기distances = [[get_dist(houses[i], chikens[j]) for i in range(len(houses))] for j in range(len(chikens))]count_min = 10e9for candidate in combinations(list(range(0, len(chikens))), m): count = 0 for j in range(len(houses)): # 각 집에서의 치킨 거리 더하기 count += min(distances[i][j] for i in candidate) count_min = min(count_min, count)print(count_min)외벽 점검전수조사를 하면 최대 len(list(permutations([1,2,3,4,5,6,7,8], 8))) * 8 * 15 * 8 = 38707200번의 연산이 필요하고 시간 내에 가능하다고 판단되어 전수조사를 진행했다.from itertools import permutationsdef get_min_workers(new_intervals, perm): start_len = len(perm) ii = 0 remaining_dist = perm.pop() while ii &amp;lt; len(new_intervals): if new_intervals[ii] &amp;lt;= remaining_dist: # 더 갈 수 있으면 remaining_dist -= new_intervals[ii] ii += 1 else: # 더 갈 수 없으면 if ii + 1 == len(new_intervals): # 마지막이면 종료 ii += 1 break if ii &amp;lt; len(new_intervals) and len(perm) != 0: remaining_dist = perm.pop() ii += 1 else: break if ii == len(new_intervals): # 모두 커버했으면 return start_len - len(perm) else: return 101def solution(n, weak, dist): intervals = [b - a for a, b in zip(weak[:-1], weak[1:])] + [(n - weak[-1]) + weak[0]] min_workers = 101 for i in range(len(intervals)): new_intervals = intervals[i:] + intervals[:i] for perm in permutations(dist): new_min = get_min_workers(new_intervals, list(perm)) if new_min &amp;lt; min_workers: min_workers = new_min if min_workers == 101: return -1 else: return min_workers" }, { "title": "AWS CLI - S3 sync 속도 개선하기", "url": "/posts/AWS_cli_S3_sync_speed_up/", "categories": "AWS", "tags": "dev", "date": "2022-01-18 00:00:00 +0900", "snippet": "AWS CLI의 sync 명령어를 통해서 S3의 데이터를 백업할 때, aws s3 sync s3://$bucket . 의 형태로 버킷단위로 sync를 진행하면 시간이 많이 걸렸습니다.sync를 할 때 파일 전송시간보다 어떤 파일을 옮겨야 할지 찾는데 시간이 더 많이 걸리는 것 같았고 네트워크 대역폭은 널널했었습니다. 이 대역폭을 가득 채우고 싶었습니다.AWS에서 아래의 두 가지 제안을 찾을 수 있었습니다.1. prefix별로 aws s3 sync 를 동시에 여러 개 실행하기기존에는 PowerShell script의 foreach를 통해 여러 개의 버킷을 순차적으로 sync하고 있었습니다.병렬적으로 실행하기 위해서 PowerShell 7부터 지원하는 ForEach-Object 명령어의 -Parallel 옵션을 사용하기로 하였고, Winget을 사용하여 PowersShell 7을 설치하여 script를 작성해보았습니다.(윈도우에 기본적으로 설치되어있던 PowerShell이 6.0부터 .NET Core를 기반으로 다양한 플랫폼을 지원하는 오픈 소스 프로젝트가 되었습니다. 그래서 PowerShell 7은 추가적으로 설치가 필요합니다.)$bucket = &quot;싱크 대상 버킷&quot;$prefix = &quot;싱크 대상 폴더&quot;$start_time = Get-Date -UFormat &quot;%Y-%m-%d %T%Z&quot;$start_date = Get-Date -UFormat &quot;%Y%m%d&quot;aws configure set s3.max_concurrent_requests 30[array] $parts = aws s3 ls s3://$bucket/$prefix/$cur_path = &quot;현재 디렉토리 경로&quot;New-Item -Path $cur_path -Name &quot;${start_date}_${bucket}_${prefix}&quot; -ItemType &quot;directory&quot;$log_path = &quot;$cur_path\\${start_date}_${bucket}_${prefix}&quot;Write-Output &quot;Syncing bucket &#39;$bucket&#39; ($start_time)...&quot; | Out-File -FilePath &quot;$log_path\\log.log&quot; -Appendforeach ($p in $parts){ if ($p -match &quot;part&quot;) { $part = (-split $p | Select-Object -Last 1).Trim(&quot;/&quot;) [array] $nums = aws s3 ls s3://$bucket/$prefix/$part/ foreach ($n in $nums) { $num = (-split $n | Select-Object -Last 1).Trim(&quot;/&quot;) if ((($num -split &quot;=&quot;) | Select-Object -Last 1) -gt &quot;130&quot;) { Write-Output &quot; $bucket)/$prefix)/$part)/$num&quot; | Out-File -FilePath &quot;$log_path\\log.log&quot; -Append } } $nums | ForEach-Object -Parallel { $n = $_ if ($n -match &quot;num&quot;) { $num = (-split $n | Select-Object -Last 1).Trim(&quot;/&quot;) if ((($num -split &quot;=&quot;) | Select-Object -Last 1) -gt &quot;130&quot;) { aws s3 sync &quot;s3://$($using:bucket)/$($using:prefix)/$($using:part)/$num&quot; &quot;로컬 디렉토리 경로\\$($using:bucket)\\$($using:prefix)\\$($using:part)\\$num&quot; 2&amp;gt;&amp;amp;1 &amp;gt; &quot;$($using:log_path)\\$($using:part)_$date.log&quot; } } } -ThrottleLimit 20 $mid_time = Get-Date -UFormat &quot;%Y-%m-%d %T%Z&quot; Write-Output &quot;current time: $mid_time, $part&quot; | Out-File -FilePath &quot;$log_path\\log.log&quot; -Append }}$end_time = Get-Date -UFormat &quot;%Y-%m-%d %T%Z&quot;Write-Output &quot;done ($end_time)&quot;Write-Output &quot;&quot; S3 대상 버킷의 prefix의 구조는 $bucket/$prefix/part=123/num=123/..의 형태입니다. ../num=123/.. 단위로 병렬적으로 sync를 하도록 구성하였습니다. aws s3 sync의 출력값들을 시간정보와 함께 파일로 저장하기위해서 prefix별로 디렉토리를 만들고 그 안에 출력값들을 저장하도록 하였습니다. num=130보다 큰 값들만 sync하도록 설정하였습니다. ForEach-Object에서 -Parallel 옵션을 통해 병렬처리를, -ThrottleLimit을 통해 동시에 실행될 수 있는 스크립트 수를 제한하였습니다. ForEach-Object 안으로 밖의 변수를 전달하기 위해 $using:을 사용하였습니다. ($bucket의 형태로는 ForEach-Object 밖의 변수를 사용할 수 없습니다.)2. AWS CLI의 max_concurrent_requests값을 수정하기max_concurrent_requests의 기본값은 10이며, S3에 한 번에 전송할 수 있는 요청수를 나타냅니다.기본값에서 실행하였을 때 시스템에 부하가 없었기에 max_concurrent_requests를 30정도로 수정하였습니다.aws configure set s3.max_concurrent_requests 30" }, { "title": "AWS CodeCommit으로 Git repo 옮기기", "url": "/posts/AWS_CodeCommit_migration/", "categories": "AWS", "tags": "dev", "date": "2022-01-18 00:00:00 +0900", "snippet": "기존에 사용하던 Git repository를 AWS CodeCommit으로 옮기고 credential helper를 이용해서 remote에 연결하는 과정을 정리하였습니다.1. Git repository를 AWS CodeCommit으로 옮기기: AWS Documentation을 따라가며 작성하였습니다. AWS User에게 적절한 권한을 준 뒤, CodeCommit을 위한 HTTPS Git credentials을 생성합니다. CodeCommit 콘솔에서 새로운 repository를 만들어줍니다. aws-codecommit-demo이라는 폴더에 bare repo를 생성합니다. git clone --mirror ssh://git_repo.git aws-codecommit-demo bare repo 폴더로 이동하여 CodeCommit 콘솔에서 확인한 URL로 bare repo를 push해줍니다. cd aws-codecommit-demo git push https://git-codecommit.ap-northeast-2.amazonaws.com/v1/repos/&amp;lt;new_repo&amp;gt; --all git push https://git-codecommit.ap-northeast-2.amazonaws.com/v1/repos/&amp;lt;new_repo&amp;gt; --tags --all 옵션을 통해 모든 브랜치를 push할 수 있습니다. 하지만 tags는 push되지 않기 때문에 --tags 옵션을 통해 한 번 더 push해줍니다. 위에서 생성한 aws-codecommit-demo이라는 폴더는 더 이상 필요하지 않기에 삭제해줍니다. 끝!2. Git credential helper 설정하기credential helper는 HTTP 프로토콜을 사용해서 remote repo에 접근할 때 매번 인증을 거치지 않게 해주는 시스템입니다. git에서는 기본적으로 cache, store, wincred와 같은 옵션을 제공하고 자세한 내용은 여기서 확인할 수 있습니다.AWS CLI에서는 HTTPS를 통한 CodeCommit 접근을 위해 CLI config의 정보를 이용할 수 있게 해주는 credential helper를 제공합니다. helper를 설정하는 방법은 document에 제시되어있습니다.저는 기본값으로 설정시 403에러가 발생해서 아래와 같이 .gitconfig파일을 직접 수정해주었습니다.[credential &quot;https://git-codecommit.ap-northeast-2.amazonaws.com&quot;] helper = !aws codecommit credential-helper --profile carvi $@ UseHttpPath = true[credential] helper = wincred3. 새로 생성한 CodeCommit repo를 remote로 추가하기 upstream추가에 앞서 지금 등록된 remote 목록을 확인해봅니다. git remote -v CodeCommit repo 주소를 remote에 “upstream”이름으로 등록합니다. git remote add upstream https://git-codecommit.ap-northeast-2.amazonaws.com/v1/repos/&amp;lt;new_repo&amp;gt; 끝! " }, { "title": "백준 단계별 - 그리디 알고리즘", "url": "/posts/BOJ_Greedy/", "categories": "Coding Test", "tags": "Algorithm", "date": "2022-01-07 00:00:00 +0900", "snippet": "문제풀이동전 0import sysinput = sys.stdin.readlinen, k = map(int, input().split())values = [int(input()) for _ in range(n)]cur_value_index = n - 1count = 0while k &amp;gt; 0: if values[cur_value_index] &amp;lt;= k: count += k // values[cur_value_index] k = k % values[cur_value_index] cur_value_index -= 1print(count)회의실 배정일단 되는대로 해봤는데, 역시나 시간초과였다.import sysinput = sys.stdin.readlinen = int(input())classes = sorted([list(map(int, input().split())) for _ in range(n)], key=lambda x: x[1])greedy_list = [0 for _ in range(max(max(x) for x in classes) + 1)]for cls in classes: fst_max = max(greedy_list[:cls[0] + 1]) snd_max = max(greedy_list[:cls[1] + 1]) if snd_max &amp;lt; fst_max + 1: greedy_list[cls[1]] = fst_max + 1print(max(greedy_list))인터넷을 참고해서 풀었는데 역시 간단한 거였다.import sysinput = sys.stdin.readlinen = int(input())classes = sorted([list(map(int, input().split())) for _ in range(n)], key=lambda x: (x[1], x[0]))count = 0ended_time = 0for cls in classes: if cls[0] &amp;gt;= ended_time: count += 1 ended_time = cls[1]print(count)ATM시간이 짧게 걸리는 사람부터 돈을 뽑으면 된다.import sysinput = sys.stdin.readlinen = int(input())times = sorted(list(map(int, input().split())))print(sum([t * (n - i) for i, t in enumerate(times)]))잃어버린 괄호”-“가 나온 이후부터는 괄호를 사용해서 식의 총합을 계속 줄일 수 있다.import sysinput = sys.stdin.readlineeqa = input().strip()minus_index = eqa.find(&quot;-&quot;)if minus_index == -1: print(sum(map(int, eqa.split(&quot;+&quot;))))else: print( sum(map(int, eqa[:minus_index].split(&quot;+&quot;))) - sum(map(int, eqa[minus_index + 1:].replace(&quot;-&quot;, &quot;+&quot;).split(&quot;+&quot;))) )주유소다음 도시까지 가는데 필요한 도로에서 쓸 연료는 그 도로 전의 도시들 중 리터당 가격이 가장 싼 곳에서 사면 된다.import sysinput = sys.stdin.readlinen_cities = int(input())roads = list(map(int, input().split()))cities = list(map(int, input().split()))cost = 0cur_min = cities[0]for i in range(n_cities - 1): cost += cur_min * roads[i] cur_min = min(cur_min, cities[i + 1])print(cost)" }, { "title": "downtime없이 MongoDB Replica Set 설정 변경하기", "url": "/posts/MongoDB_Replica_Set_reconfig_without_downtime/", "categories": "MongoDB", "tags": "dev", "date": "2022-01-06 00:00:00 +0900", "snippet": "상황현재 상황은 docker로 MongoDB가 실행되고 있으며, PSA 구조(Primary 1개, Secondary 1개, Arbiter 1개)의 Replica Set으로 구성되어 있는 상황입니다. 그리고 변경해야하는 사항들은 다음과 같습니다. Replica Set의 host 주소를 IP에서 URI로 변경하기 mongod.conf 파일의 security.keyFile을 활성화하기 mongod.conf 파일의 net.tls를 활성화하기 docker-compose.yaml 파일의 extra_hosts의 주소를 IP에서 URI로 변경하기해결첫 번째 시도 Arbiter를 내린 후 secrity.keyFile 활성화, net.tls 활성화, extra_hosts 변경 후 restart 해보았습니다. → lastHeartbeatMessage: &#39;Connection closed by peer’ 로 Arbiter에 연결되지 않았습니다. → security가 활성화되면서 기존의 security가 비활성화된 Primary와 Secondary가 Aribiter 연결에 실패한 것이 아닐까 생각이 되어서 net.tls 활성화, extra_hosts 변경만 하였더니 정상적으로 연결되었습니다. 두 번째 시도 MongoDB 문서를 참고해서 downtime없이 security.keyFile 활성화를 시도하였습니다. → config파일의 security.transitionToAuth 를 true로 설정하고 secrity.keyFile을 설정 후 restart 하였습니다. → rs.status() 을 통해 정상적으로 서로 연결된 것을 확인하였고 문서를 따라 나머지 절차도 진행하였습니다. → 성공! MongoDB 문서를 참고해서 downtime없이 rs.reconfig()를 진행하였습니다. cfg = rs.config() cfg.members[0].host = &quot;new hostname&quot; rs.reconfig(cfg) → 위의 방법으로 Secondary와 Arbiter를 먼저 수정하였습니다. → Primary를 rs.stepDown()하여 Secondary로 변경 후 새로운 Primary에서 위의 방법으로 기존 Primary의 host도 변경하였습니다. → 성공! MongoDB 문서를 참고해서 downtime없이 TLS 설정을 하였습니다. net: tls: mode: allowTLS PEMKeyFile: &amp;lt;path to TLS/SSL certificate and key PEM file&amp;gt; CAFile: &amp;lt;path to root CA PEM file&amp;gt; → 먼저 config파일의 tls를 allowTLS모드로 변경후 Secondary, Arbiter, Primary 순으로 restart 해주었습니다. → db.adminCommand( { setParameter: 1, tlsMode: &quot;preferTLS&quot; } ) 를 통해 tlsMode를 변경하였고, db.adminCommand( { getParameter : 1, &quot;tlsMode&quot; : 1 } ) 를 통해 현재 tlsMode parameter가 preferTLS로 되어있는 것을 확인하였습니다. → 같은 방법으로 requireTLS모드로 변경하였습니다. → config의 tls.mode도 requireTLS로 변경하여 restart될 때 문제가 없도록 하였습니다. → 임의로 변경된 config파일로 restart 해보았때 정상적으로 작동하였습니다. → 성공! +원했던대로 downtime없이 설정을 완료할 수 있었습니다. member 중 하나가 down되어도 되는 Replica Set의 장점을 잘 사용할 수 있었던 경험이었습니다." }, { "title": "이것이 취업을 위한 코딩 테스트다 with 파이썬 - Tips", "url": "/posts/python_for_coding_test_Tips/", "categories": "Coding Test", "tags": "Tips", "date": "2022-01-03 00:00:00 +0900", "snippet": " 이것이 취업을 위한 코딩 테스트다 with 파이썬을 읽고 필요한 부분을 요약 정리하였습니다.코딩 테스트 환경Jupyter나 VSCode를 이용해서 코테 문제를 풀었었는데, 이 책에서 온라인 IDE로 리플릿을 소개해주어서 사용해해보려고 합니다.복잡도1. 시간 복잡도보통 코딩 테스트 문제의 시간 제한은 1 ~ 5초 정도로 연산 횟수가 10억을 넘어가지 않도록 하는 것이 필요합니다. 1초에 1~2000만 번의 연산을 수행한다고 가정하면 안정적입니다. 문제를 풀 때 책에서 소개한 다음의 예시 몇 가지를 생각하는 것이 필요합니다. N=500: 시간 복잡도가 O(N^3)인 알고리즘을 설계 N=2000: 시간 복잡도가 O(N^2)인 알고리즘을 설계 N=100,000: 시간 복잡도가 O(N log N)인 알고리즘을 설계 N=10,000,000: 시간 복잡도가 O(N)인 알고리즘을 설계 2. 공간 복잡도 보통 코딩 테스트 문제의 메모리 제한은 128MB ~ 512MB 정도로 데이터 개수가 1000만개 이상 넘어가지 않도록 하는 것이 필요합니다. 컴퓨터공학 지식 Technical Interview Guidelines for BeginnersPython tips 소수점 값을 비교하는 작업이 필요하면 round() 함수를 이용하는게 좋습니다. (컴퓨터가 실수를 정확하게 표현하지 못하기 때문에) 리스트 관련 매서드의 시간복잡도 append(): O(1) sort(): O(N log N) reverse(): O(N) insert(): O(N) count(): O(N) remove(): O(N) 집합 관련 매서드의 시간복잡도 add(): O(1) remove(): O(1) " }, { "title": "이것이 취업을 위한 코딩 테스트다 with 파이썬 - Greedy", "url": "/posts/python_for_coding_test_Greedy/", "categories": "Coding Test", "tags": "Algorithm", "date": "2022-01-03 00:00:00 +0900", "snippet": " 이것이 취업을 위한 코딩 테스트다 with 파이썬을 읽고 필요한 부분을 요약 정리하였습니다.Greedy현재 상황에서 가장 좋아 보이는 것만을 선택하는 알고리즘큰 수의 법칙# time: 7minsimport sysinput = sys.stdin.readlinen, m, k = map(int, input().split())nums = sorted(list(map(int, input().split())), reverse=True)print( (k * nums[0] + nums[1]) * (m // (k + 1)) + nums[0] * (m % (k + 1)))숫자 카드 게임# time: 4minsimport sysinput = sys.stdin.readlinen, m = map(int, input().split())mat = [list(map(int, input().split())) for _ in range(n)]print(max([min(row) for row in mat]))1이 될 때까지# time: 6minsimport sysinput = sys.stdin.readlinen, k = map(int, input().split())count = 0while n != 1: if n % k == 0: n //= k else: n -= 1 count += 1print(count)모험가 길드# time: 8minsimport sysinput = sys.stdin.readlinen = int(input())advs = sorted(list(map(int, input().split())))members = 1count = 0for adv in advs: if adv &amp;lt;= members: members = 1 count += 1 else: members += 1print(count)곱하기 혹은 더하기# time: 6minsimport sysinput = sys.stdin.readlinenums = list(map(int, str(input().strip())))out = nums[0]for i in range(1, len(nums)): if nums[i] &amp;lt;= 1 or out &amp;lt;= 1: out += nums[i] else: out *= nums[i]print(out)문자열 뒤집기# time: 8minsimport sysinput = sys.stdin.readlinechars = str(input().strip())count = 0for i in range(1, len(chars)): if chars[i] != chars[i - 1]: count += 1if chars[0] == chars[-1]: print(count // 2)else: print(count // 2 + 1)만들 수 없는 금액조금 어려웠다.. 다시 풀어보기!# time: 25minsimport sysinput = sys.stdin.readlinen = int(input())nums = sorted(list(map(int, input().split())))def get_impossible_min(): prev_range = [0, nums[0]] next_range = [0, 0] for i in range(1, n): next_range = [prev_range[0] + nums[i], prev_range[1] + nums[i]] if prev_range[1] + 1 &amp;lt; next_range[0]: return prev_range[1] + 1 else: prev_range = [0, next_range[1]] return next_range[1] + 1print(get_impossible_min())이걸 더 간단히하면 이렇게 된다.import sysinput = sys.stdin.readlinen = int(input())nums = sorted(list(map(int, input().split())))def get_impossible_min(): possible_min = 0 for num in nums: if possible_min + 1 &amp;lt; num: return possible_min + 1 else: possible_min += num return possible_min + 1print(get_impossible_min())볼링공 고르기전체 경우의 수에서 두 사람이 같은 무게를 고르는 경우의 수들을 빼주었다.# time: 13minsimport sysinput = sys.stdin.readlinen, m = map(int, input().split())balls = list(map(int, input().split()))counts = [0 for _ in range(m + 1)]for ball in balls: counts[ball] += 1out = n * (n - 1) // 2for c in counts: if c &amp;gt; 1: out -= (c * (c - 1) // 2)print(out)무지의 먹방 라이브시간이 많이 걸렸다.# time: &amp;gt; 60minsdef solution(food_times, k): sorted_food_times = sorted(food_times) prev_food_time = 0 for i, food_time in enumerate(sorted_food_times): val = (food_time - prev_food_time) * (len(sorted_food_times) - i) if val &amp;gt; k: break else: k -= val prev_food_time = food_time remained_food = [] for i, food_time in enumerate(food_times): if food_time - prev_food_time &amp;gt; 0: remained_food.append(i + 1) if len(remained_food) == 0: return -1 else: return remained_food[k % len(remained_food)]책에서 해설로 제시된 heapq를 이용한 풀이는 다음과 같다.메모리와 실행시간 모두 위의 풀이가 더 좋았으며, heapq에서 작은 값은 계속 작은 위치를 유지함으로 굳이 heapq를 사용할 필요는 없는 것 같다.import heapqdef solution(food_times, k): if sum(food_times) &amp;lt;= k: return -1 hq = [] for food_time in enumerate(food_times): heapq.heappush(hq, (food_time, i + 1)) sum_values = 0 # 먹기 위해 사용한 시간 previous = 0 # 직전에 다 먹은 음식 시간 length = len(food_times) # 남은 음식 개수 # sum_value + (현재의 음식 시간 - 이전 음식 시간) * 현재 음식 개수와 k 비교 # while sum_value + ((hq[0][0] - previous) * length) &amp;lt;= k: now = heapq.heappop(hq)[0] sum_value += (now - previous) * length length -= 1 # 다 먹은 음식 제외 previous = now # 이전 음식 시간 재설정 # 남은 음식 중에서 몇 번쨰 음식인지 확인하여 출력 result = sorted(hq, key=lambda x: x[1]) return result[(k - sum_value) % length][1]" }, { "title": "Python - 여러가지 list copy 방법", "url": "/posts/python_list_copy/", "categories": "Python", "tags": "Python", "date": "2021-12-17 00:00:00 +0900", "snippet": "Python list에 대해서 lst_a = lst lst_b = lst[:] lst_c = copy.copy(lst) lst_d = copy.deepcopy(lst)copy 방법들이 어떤 차이점이 있는지 자세히 알고싶어서 검색하던 중 설명이 잘 된 글을 찾게되어 아래에 공유합니다. Assignment 부분도 비교해주어서 좋았습니다.Python: Assignment vs Shallow Copy vs Deep Copy" }, { "title": "AWS - ATS signed data endpoint", "url": "/posts/aws_ats_endpoint/", "categories": "AWS", "tags": "AWS", "date": "2021-12-03 00:00:00 +0900", "snippet": "1. 문제AWS IoT shadow값을 업데이트하는 과정에서 SSL validation 에러가 발생하였습니다. 코드 client_iot = boto3.client(&quot;iot-data&quot;) client_iot.update_thing_shadow( thingName=thing_name, payload=json.dumps(shadow_state_desired) ) 발생한 에러 메시지 &#39;SSL validation failed for https://data.iot.ap-northeast-2.amazonaws.com/things/../shadow [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)&#39; 인증서정보 2. 원인사용중이던 Lambda layer를 업데이트하고 인증 문제가 발생하였기 때문에 달라진 점을 찾아보았습니다.Requests library가 문제가 된 것으로 보였고, 버전이 requests.version=&#39;2.24.0&#39; 에서 requests.version=&#39;2.26.0&#39;으로 변경된 것을 확인하였습니다. 이에 따라 certifi의 버전이 certifi.version=&#39;2020.06.20&#39;에서 certifi.version=&#39;2021.10.08&#39; 으로 변경된 것 또한 확인할 수 있었습니다.certifi는 Mozilla’s carefully curated collection of Root Certificates을 제공해줍니다. 그래서 Mozilla의 Root CA 목록에 변화가 있는지를 찾아보았고, distrust of Symantec root certificates 이슈를 확인하였습니다. 이슈는 Symantec이 SSL인증서를 부적절하게 발급한 것이 Google과 Mozilla에 의해 확인되었고, 업계에서는 Symantec을 신뢰하지 않게되었다는 내용이었습니다.AWS IoT shadow 업데이트 과정에서 문제가 되었던 인증서의 발급자인 VeriSign Class 3 Public Primary Certification Authority - G5 는 2020년 12월에 Mozilla의 목록에서 제거된 것을 확인할 수 있었습니다.3. 해결AWS는 IoT의 data endpoint로 기존의 VeriSign signed data endpoint 대신 ATS signed data endpoint를 사용할 것을 강력하게 권장하고 있습니다.ATS endpoint는 다양한 방법으로 얻을 수 있으며 저는 boto3의 describe_endpoint를 통해서 ATS endpoint 주소를 구하였고, 기존의 코드를 아래와 같이 변경하였습니다.def get_ATS_endpoint(): return boto3.client(&quot;iot&quot;).describe_endpoint( endpointType=&quot;iot:Data-ATS&quot; )[&quot;endpointAddress&quot;]client_iot = boto3.client(&quot;iot-data&quot;, endpoint_url=f&quot;https://{get_ATS_endpoint()}&quot;)client_iot.update_thing_shadow( thingName=thing_name, payload=json.dumps(shadow_state_desired))그 결과 SSL validation을 실패하지않고 정상적으로 shadow를 업데이트하는 것을 확인할 수 있었습니다." }, { "title": "AWS - Lambda Layer 만들기", "url": "/posts/AWS_lambda_layer/", "categories": "AWS", "tags": "AWS", "date": "2021-11-02 00:00:00 +0900", "snippet": "Lamdba에서 numpy와 같은 외부 라이브러리를 사용하기위해서 layer를 사용합니다. 필요한 라이브러리를 패키징해서 layer로 올려놓으면 Lambda 함수에서 해당 layer를 사용해서 함수를 실행할 수 있습니다.AWS에서 제공하는 runtime 언어별로 layer를 만드는 방법을 참고하여 layer를 생성해보겠습니다. 저는 AmazonLinux2 기반의 Docker Image에서 Python을 기준으로 layer를 생성하였습니다. zip파일 구조 확인하기 AWS Guide 에 따르면 layer 코드를 .zip file archive로 만들어야합니다. 만약 layer가 native code binary를 포함한다면 Amazon Linux와 호환되도록 Linux machine에서 compile &amp;amp; build 해야합니다. 아래와 같은 구조로 .zip file archive를 생성하면 됩니다. pipenv를 이용해서 가상환경에 필요한 패키지 설치하기 pipenv install 또는 .Pipfile을 이용해서 패키지를 설치해줍니다. 설치된 패키지 위치 확인하기 pipenv --venv 를 이용하면 가상환경이 만들어진 위치를 확인할 수 있고 /root/.local/share/virtualenvs/try-Hjhggp_2/lib/python3.9/site-packages 위치에 패키지들이 설치된 것을 확인할 수 있습니다. pipenv --venv -&amp;gt; /root/.local/share/virtualenvs/try-Hjhggp_2 설치된 패키지를 zip파일로 만들기 아래 스크립트를 통해 pipenv에서 만들어진 site-packages를 새로 생성한 tmp폴더안에 구조를 지켜서 복사해서 tmp폴더를 zip해줍니다. mkdir tmp mkdir -p ./tmp/python/lib/python3.9 cp -r /root/.local/share/virtualenvs/try-Hjhggp_2/lib/python3.9/site-packages ./tmp/python/lib/python3.9/site-packages cd tmp zip -r9 ../my-package.zip . 끝! 이제 생성된 zip파일을 layer에 업로드하면 됩니다." }, { "title": "MongoDB &amp; certbot으로 certificateKeyFile 만들기", "url": "/posts/mongodb_and_certbot_create_pem/", "categories": "MongoDB", "tags": "MongoDB", "date": "2021-10-12 00:00:00 +0900", "snippet": "MongoDB를 Replica Set 형태로 배포할 때 DB URL에 TLS로 접근할 수 있도록 하려고 합니다.다음은 MongoDB Replica Set을 만들때 사용하는 config파일의 tls 설정부분입니다.net: port: xxxx bindIp: 0.0.0.0 tls: mode: requireTLS certificateKeyFile: /data/mongo.pem CAFile: /data/fullca.pem이 부분에 사용할 mongo.pem파일과 fullca.pem파일을 만들어보겠습니다.certificateKeyFile 만들기 cerbot으로 도메인에 대한 인증서 발급받은 후 생성되는 파일 4개를 확인 certbot으로 도메인에 대한 인증서를 발급받으면 cert.pem, chain.pem, fullchain.pem, privkey.pem 4개의 파일이 생성됩니다. privkey.pem private key 를 가지고 있습니다. cert.pem cert 1 Issuer: C = US, O = Let’s Encrypt, CN = R3 Subject: CN = chain.pem cert 2 Issuer: C = US, O = Internet Security Research Group, CN = ISRG Root X1 Subject: C = US, O = Let’s Encrypt, CN = R3 cert 3 Issuer: O = Digital Signature Trust Co., CN = DST Root CA X3 Subject: C = US, O = Internet Security Research Group, CN = ISRG Root X1 fullchain.pem cert.pem, chain.pem 두 파일을 합쳐놓은 파일입니다. fullca.pem 만들기 도메인에서 RootCA까지의 chain을 모두 저장하는 fullca.pem이라는 파일을 먼저 만들겠습니다. DST Root CA X3를 사용할 때에는 fullchain.pem에 “self-signed” DST Root CA X3 인증서를 추가하여 인증 chain을 완성해서 fullca.pem을 만들었습니다. #!/bin/bash here=$(cd &quot;$(dirname &quot;$(readlink -f &quot;$0&quot;)&quot;)&quot;; pwd) wherekeys=/etc/letsencrypt/live/&amp;lt;domain_URL&amp;gt; wget --directory-prefix=&quot;$here/../&quot; http://apps.identrust.com/roots/dstrootcax3.p7c openssl pkcs7 -inform der -in &quot;$here/../dstrootcax3.p7c&quot; -out &quot;$here/../dstrootcax3.pem&quot; -print_certs cp &quot;$wherekeys/fullchain.pem&quot; &quot;$here/../fullca.pem&quot; cat &quot;$here/../dstrootcax3.pem&quot; &amp;gt;&amp;gt; &quot;$here/../fullca.pem&quot; cat &quot;$wherekeys/privkey.pem&quot; &quot;$here/../fullca.pem&quot; &amp;gt; &quot;$here/../mongo.pem&quot; 하지만 2021-09-30에 Let’s encrypt에서 DST Root CA X3 사용이 중지됨에 따라 기존 방법으로는 인증이 되지 않았습니다. Let’s Encrypt의 DST Root CA X3 만료 그래서 cert.pem + chain.pem의 cert 2 + isrgrootx1.pem(self-signed ISRG Root X1 인증서) 를 통해 fullca.pem을 만들었습니다. (self-signed ISRG Root X1 인증서는 https://letsencrypt.org/certificates/ 의 .pem 파일을 이용하였습니다.) #!/bin/bash here=$(cd &quot;$(dirname &quot;$(readlink -f &quot;$0&quot;)&quot;)&quot;; pwd) wherekeys=/etc/letsencrypt/live/&amp;lt;domain_URL&amp;gt; wget -O &quot;$here/../isrgrootx1.pem&quot; https://letsencrypt.org/certs/isrgrootx1.pem cp &quot;$wherekeys/cert.pem&quot; &quot;$here/../fullca.pem&quot; csplit -s -z -f &quot;$here/../chain-&quot; &quot;$wherekeys/chain.pem&quot; &quot;/-----BEGIN CERTIFICATE-----/&quot; &quot;{*}&quot; cat &quot;$here/../chain-00&quot; &amp;gt;&amp;gt; &quot;$here/../fullca.pem&quot; cat &quot;$here/../isrgrootx1.pem&quot; &amp;gt;&amp;gt; &quot;$here/../fullca.pem&quot; cat &quot;$wherekeys/privkey.pem&quot; &quot;$here/../fullca.pem&quot; &amp;gt; &quot;$here/../mongo.pem&quot; rm $here/../chain-* : 4개의 파일로 mongo.pem를 생성하는 스크립트입니다. fullca.pem이 잘 생성되었는지 확인해보기 생성된 fullca.pem을 통해서 cert.pem이 인증되는 것을 확인할 수 있습니다. openssl verify -CAfile fullca.pem cert.pem -&amp;gt; cert.pem: OK mongo.pem 만들기 privkey.pem을 fullca.pem에 더해 mongo.pem을 만듭니다. 이제 생성한 fullca.pem파일과 mongo.pem파일을 config파일에서 명시한 위치에 옮겨서 Replica Set을 만드는데 사용할 수 있습니다.+ 참고인증서 갱신certbot을 통해 인증서를 발급받으면 기본적으로 crontab을 이용해 매일 2번 renew가 실행되며, 만기일이 30일보다 적게 남은 인증서가 업데이트됩니다.인증서 확인하기 openssl x509 -text -noout -in cert.pem cert.pem파일의 Validity, Issuer, Subject 등의 정보를 확인할 수 있습니다. openssl verify -CAfile fullca.pem cert.pem CAfile의 Chain of trust로 인증서를 인증할 수 있는지 확인할 수 있습니다. openssl s_client -connect &amp;lt;Domain URL&amp;gt; 2&amp;gt; /dev/null | openssl x509 -noout -dates 도메인의 URL로부터 인증서 만기일을 확인할 수 있습니다. sudo openssl x509 -dates -noout -in /etc/letsencrypt/live/&amp;lt;Domain URL&amp;gt;/fullchain.pem .pem파일로부터 인증서 만기일을 확인할 수 있습니다. 참고자료 https://carpfish.tistory.com/entry/OpenSSL-Lets-Encrypt-인증서-Chain-verify-방법 MongoDB Shell에서 TLS상태 확인하기db.serverStatus()로 확인할 수 있습니다. security.SSLServerHasCertificateAuthority false인 경우 CA파일이 제대로 읽어지지 않은 것이므로 Root CA를 포함한 CA chain파일을 넣어주면 됩니다. security.SSLServerCertificateExpirationDate 인증서의 만기일을 확인할 수 있습니다. 인증서 생성(manual) dns plugin을 제공하지 않는 곳에서는 --manual옵션으로 인증서를 생성해야 합니다. certbot certonly --manual --preferred-challenges dns --cert-name CERT-NAME -d DOMAINS 요청된 값을 TXT record에 추가하면 됩니다. 정상적으로 등록이 되었다면 아래와 같은 메시지를 확인할 수 있습니다. 메시지 내용처럼 --manual로 생성한 인증서는 자동으로 renew되지 않습니다." }, { "title": "Let’s Encrypt의 DST Root CA X3 만료", "url": "/posts/lets_encrypt_expired_root_ca/", "categories": "Tools", "tags": "Other", "date": "2021-10-07 00:00:00 +0900", "snippet": "Let’s Encrypt에서 발급받은 인증서를 사용하던 중 인증에 문제가 발생하여 알아보니 Root CA 하나가 만료되어 발생한 문제였습니다.Let’s Encrypt가 2015년에 서비스를 시작할 때, root certificate(A self-signed certificate controlled by a certificate authority)로 IdenTrust라는 곳의 DST Root X3를 통해서 cross-signed된 ISRG Root X1을 사용하였습니다.이후 2021-10-01부터는 DST Root CA X3를 만료하고, ISRG Root X1을 사용한다고 합니다. (일부 Android device에 대해서는 2024년 9월까지 DST Root CA X3 지원) 참고자료 DST Root CA X3 Expiration (September 2021) Production Chain Changes 안전한 SSL/TLS를 운영하기 위해 알아야 하는 것들 " }, { "title": "NAS(Synology) RAID 종류 비교", "url": "/posts/nas_raid/", "categories": "Tools", "tags": "Others", "date": "2021-09-14 00:00:00 +0900", "snippet": "RAID란?RAID(Redundant Array of Inexpensive/Independent Disk)는 디스크를 여러 개를 결합해서 데이터를 저장하는 기술입니다.여러가지 방법으로 데이터를 저장할 수 있고, 그 방법에 따라 성능과 가용성이 달라집니다. 하지만 백업 용도로 사용하는 것은 아닙니다.RAID 종류(아래 이미지에서 저장하고자하는 데이터는 110101입니다) RAID 0 하나의 데이터를 나누어서 여러 디스크에 저장합니다. 여러 디스크의 대역폭을 사용할 수 있으므로, 속도도 빨라지고 저장가능한 전체 용량도 전체 디스크 용량의 합만큼 증가합니다. 하지만, 하나의 디스크라도 손상된다면 전체 데이터를 읽을 수 없게 됩니다. RAID 1 RAID 0과는 반대로 데이터를 여러 디스크에 동일하게 저장합니다. 저장가능한 전체 용량은 디스크 1개의 용량과 같게되는 단점이 있습니다. 하지만, 하나의 디스크가 손상되더라도 데이터를 복구할 수 있기에 손상된 디스크를 제거하고 새로운 디스크를 장착하면 가용성을 잃지 않고 데이터를 운영할 수 있습니다. RAID 5 1개의 parity를 함께 저장합니다. 예를 들어 한 줄에 다음과 같이 110101를 저장할 때 1 + 1 + parity = 짝수, 0 + 1 + parity = 짝수를 만족시키는 parity를 여러 디스크에 나누어 저장하면, 하나의 디스크가 없더라도 parity를 통해 해당 디스크의 데이터를 복구할 수 있습니다. 이 경우 하나의 디스크가 손상되어도 가용성을 잃지 않고 데이터를 운영할 수 있습니다. RAID 6 2개의 parity를 함께 저장합니다. RAID 5와 유사하지만 parity를 두 개의 디스크에 저장해서 두 개의 디스크가 손상되더라도 가용성을 잃지 않게 해줍니다. RAID 10 RAID 1과 RAID 0을 결합한 방법으로 RAID 1로 구성한 그룹을 RAID 0으로 다시 구성합니다. SHR-1, SHR-2 Synology에서 제공하는 기술로 서로 크기가 다른 디스크들로 RAID를 구성할 때 유용합니다. 아래에 4TB용량의 디스크들로 RAID를 구성할 때 사용할 수 있는 전체 용량과 복구할 수 있는 용량을 정리하였습니다.Synology의 RAID 유형 변경 제한Synology에서 데이터 손실없이 변경가능한 경우는 다음과 같습니다. Basic(RAID 없음)에서 RAID 1, RAID 5로 변경 RAID 1에서 RAID 5로 변경 RAID 5에서 RAID 6으로 변경 SHR-1에서 SHR-2로 변경" }, { "title": "Docker + VSCode Remote Container로 개발환경 설정하기", "url": "/posts/docker_vscode_remote_container/", "categories": "Tools", "tags": "Docker", "date": "2021-08-13 00:00:00 +0900", "snippet": "다음과 같은 장점들을 기대하며 Docker를 사용해서 개발환경을 설정해보았습니다. 개발하는 코드가 서비스될 환경과 비슷한 환경에서 개발할 수 있다. 여러 사람이 동일한 환경에서 개발할 수 있다. 쉽게 수정하고 재구성할 수 있다.아래의 필요한 조건들에 맞게 구성하였습니다. OS: AmazonLinux2 설치할 항목: Python3.8 + 라이브러리들 AWS CLI, serverless VSCode, JupyterLab 로컬환경의 Git working directory를 마운트 로컬환경의 ~/.ssh, ~/.aws에 있는 설정을 사용하기1. Docker Image 만들기Docker file을 이용해서 amazonlinux_dev라는 이름의 Image를 생성해줍니다.docker build --tag=amazonlinux_dev . Dockerfile FROM amazonlinux ENV LANG=en_US.UTF-8 # Update yum and install packages RUN yum update -y &amp;amp;&amp;amp; yum install -y zip gzip unzip which tar vim git tar wget openssl util-linux-user shadow-utils sudo # Install awscli2 RUN curl &quot;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip&quot; -o &quot;awscliv2.zip&quot; \\ &amp;amp;&amp;amp; unzip awscliv2.zip \\ &amp;amp;&amp;amp; ./aws/install # Install python3.8 RUN amazon-linux-extras install -y python3.8 # Install fish shell RUN cd /etc/yum.repos.d/ \\ &amp;amp;&amp;amp; wget https://download.opensuse.org/repositories/shells:fish/CentOS_7/shells:fish.repo \\ &amp;amp;&amp;amp; yum install -y fish \\ &amp;amp;&amp;amp; chsh -s /usr/bin/fish # Set git RUN git config --global core.autocrlf input # Set fish SHELL [&quot;/usr/bin/fish&quot;, &quot;--command&quot;] RUN curl https://raw.githubusercontent.com/oh-my-fish/oh-my-fish/master/bin/install &amp;gt; omf-install \\ &amp;amp;&amp;amp; fish omf-install -y --noninteractive \\ &amp;amp;&amp;amp; mkdir -p ~/.config/fish/functions/ \\ &amp;amp;&amp;amp; touch ~/.config/fish/functions/fish_right_prompt.fish \\ &amp;amp;&amp;amp; printf &quot;function fish_right_prompt -d \\&quot;Write out the right prompt\\&quot;\\n date &#39;+%%m-%%d %%H:%%M:%%S&#39;\\nend\\n&quot; &amp;gt; ~/.config/fish/functions/fish_right_prompt.fish \\ &amp;amp;&amp;amp; source ~/.config/fish/conf.d/omf.fish # Install Node.js &amp;amp; npm &amp;amp; serverless RUN curl -fsSL https://rpm.nodesource.com/setup_lts.x | bash - \\ &amp;amp;&amp;amp; yum install -y nodejs \\ &amp;amp;&amp;amp; npm install -g serverless # Install pipenv WORKDIR /app/ COPY Pipfile Pipfile.lock .env /app/ RUN python3.8 -m pip install --no-cache-dir --upgrade pip pipenv \\ &amp;amp;&amp;amp; pipenv install --deploy --ignore-pipfile --dev \\ &amp;amp;&amp;amp; pipenv --clear COPY ./set_ssh_and_aws.sh ./set_ssh_and_aws.sh amazonlinux를 기반으로 docker image 생성 yum을 통해 필요한 package들을 설치 awscli2 설치 amazon-linux-extras를 통해 제공되는 python3.8을 설치 CentOS_7를 위해 제공되는 방법으로 fish shell 설치(amazon linux 2는 centos7, amazon linux 1은 centos6 으로), oh-my-fish 설치 git autocrlf 설정 oh-my-fish 설치 및 설정 shell의 라인 오른쪽에 시간을 표시하기 위해 fish function을 추가 생성 Node.js, npm, serverless 설치 pipenv 설치 및 /app/ 위치에 pipenv install Pipfile을 이용해 미리 생성된 Pipfile.lock을 사용 Pipenv를 실행할 때 사용할 환경변수를 저장한 .env를 사용 ssh, aws 관련 파일을 복사하는 script를 복사 2. VSCode에서 실행할 docker-compose.yaml 만들기생성한 amazonlinux_dev 이미지를 기반으로 docker-compose yaml을 작성합니다. docker-compose.yaml version: &quot;3.8&quot; services: analyzer: image: amazonlinux_dev:latest entrypoint: [&quot;/bin/sh&quot;, &quot;-c&quot;] command: [&quot;/app/set_ssh_and_aws.sh &amp;amp;&amp;amp; pipenv run python3.8 -m jupyter lab --ip=0.0.0.0 --port=8888 --allow-root --no-browser --NotebookApp.password=&#39;sha1:d99ebe6398a3:5fbfb3f2133200fad796640c88e5ff5c3d11d9d8&#39;&quot;] ports: - 8899:8888 logging: driver: json-file #journald restart: always volumes: - repos:/app/repos - C://Users//USER//.ssh:/app/ssh_local:ro - C://Users//USER//.aws:/app/aws_local:ro volumes: repos: name: repos driver: local driver_opts: type: none o: bind device: &quot;C://Users//USER//Documents//mount_dir&quot; : script를 통해 SSH, AWS CLI 설정파일을 복사하고, pipenv를 통해 jupyter lab을 8899포트에서 열도록 하였습니다. –NotebookApp.password는 Jupyter에서 sha1 algorithm으로 생성 from notebook.auth import passwd passwd(algorithm=&quot;sha1&quot;) -&amp;gt; Enter password: amazon_dev -&amp;gt; return: &#39;sha1:d99ebe6398a3:5fbfb3f2133200fad796640c88e5ff5c3d11d9d8&#39; –ip 0.0.0.0 모든 IP에 대해 접근을 허용 volume.repos.driver_opts.device 마운트할 directory의 경로를 입력 secrets : ssh_config, aws_config, aws_credential 정보를 secrets를 통해 container 내부로 전달 ssh, aws 관련 설정 ssh key는 local SSH agent를 통해 공유할 수 있습니다. https://code.visualstudio.com/docs/remote/containers#_using-ssh-keys .ssh/config파일은 별도로 생성해 주어야 해서 script를 작성하였습니다. set_ssh_and_aws.sh #!/bin/bash sudo cp -R /app/ssh_local/. ~/.ssh/ sudo cp -R /app/aws_local/. ~/.aws/ sudo chmod 0700 ~/.ssh sudo chmod 0600 ~/.ssh/* sudo find ~/.ssh -name &quot;*.pub&quot; -exec chmod 0644 {} + sudo chmod 0700 ~/.aws sudo chmod 0600 ~/.aws/* 3. VSCode를 설정해줄 .devcontainer.json 만들기VSCode를 container에 연결할 때 “Remote - Containers” Extension을 사용합니다.Container를 연결하는 방법 중 두 가지를 소개하겠습니다. &amp;gt;Remote-Containers: Open Folder in Container... 를 통해 .devcontainer.json파일이 있는 폴더를 선택합니다. .devcontainer.json파일을 통해 VSCode를 설정하고 container를 만들어 실행시킬 수 있습니다. Document를 참조하여 extension들과 사용할 docker-compose파일, work folder, phthon path 등을 설정하였습니다. { &quot;name&quot;: &quot;amazon_dev-container&quot;, &quot;dockerComposeFile&quot;: [&quot;./docker-compose.yaml&quot;], &quot;service&quot;: &quot;analyzer&quot;, &quot;shutdownAction&quot;:&quot;none&quot;, &quot;workspaceFolder&quot;: &quot;/app/repos&quot;, &quot;settings&quot;: { &quot;python.pythonPath&quot;: &quot;/usr/local/bin/python&quot; }, &quot;extensions&quot;: [ &quot;ms-python.python&quot;, &quot;ms-python.vscode-pylance&quot;, &quot;ms-toolsai.jupyter&quot;, &quot;mhutchie.git-graph&quot;, &quot;eamodio.gitlens&quot; ] } &amp;gt;Remote-Containers: Attach to Running Container...를 통해 이미 실행 중인 container에 연결합니다. 이미 실행되고 있는 container가 있을 때 attatch하여 사용할 수 있습니다. 추가 개선하기 현재 로컬환경의 OS는 Windows이고 WSL2 backend로 Docker가 실행되고 있습니다. Docker container의 메모리 점유율이 높아지면 컴퓨터 사용이 불편해져서, WSL에서 사용할 수 있는 컴퓨터 자원을 제한하였습니다. %UserProfile% directory에 있는 .wslconfig 파일의 내용을 수정해주면 되며, 설치된 모든 WSL2 버전의 Linux distributions에 적용됩니다. .wslconfig [wsl2] memory=6GB # Limits VM memory in WSL 2 to 6 GB processors=6 # Makes the WSL 2 VM use six virtual processors " }, { "title": "DynamoDB - Attribute vs Key", "url": "/posts/dynamodb_attribute_vs_key/", "categories": "AWS", "tags": "AWS", "date": "2021-08-09 00:00:00 +0900", "snippet": "DynamoDB scan에서 FilterExpression으로 Attr와 Key 둘 다 작동하였고 어떤 점이 다른지 궁금해서 찾아보았습니다. 두 개는 비슷하지만 목적이 다른 class였습니다.DynamoDB의 기본 구성요소DynamoDB는 다음과 같은 기본적인 요소들로 구성되어 있습니다. Tables data의 collection이며 0개 이상의 item을 가지고 있음 Items attributes의 group이마 0개 이상의 attributes로 구성되어 있음 Attributes 기초적인 data element로 다른 DB system의 fields 또는 columns와 비슷함 Primary Key table에서 각각의 item을 유일하게 결정해주는 값으로 다른 item은 같은 primary key를 가질 수 없습니다. primary key에는 다음 두 종류가 있습니다. Partition key 하나의 attribute로 구성됩니다. (partition key) Partition key and sort key 두 개의 attribute로 구성됩니다. (partition key, sort key) 이 경우 다른 item이 같은 partition key를 가질 수는 있으나, sort key까지 같을 수는 없습니다. Attr vs KeyBoto3 문서를 참고하면 다음과 같은 설명을 볼 수 있습니다. The boto3.dynamodb.conditions.Key should be used when the condition is related to the key of the item. The boto3.dynamodb.conditions.Attr should be used when the condition is related to an attribute of the item:Key는 key와 관련되더 있을 때, Attr는 attribute와 관련되어 있을 때 사용하라고 합니다.query, scan에 대한 설명에서도 다음과 같이 key에 대해서는 Key를 사용하고 attribute에 대해서는 Attr를 사용하라고 합니다. FilterExpression (condition from boto3.dynamodb.conditions.Attr method) KeyConditionExpression (condition from boto3.dynamodb.conditions.Key method)하지만 이 글의 시작부분처럼 Attr와 Key class가 모두 사용가능할 때가 있었습니다. 그래서 소스코드를 좀 더 살펴보았습니다. boto3.dynamodb.conditions.Key class Key(AttributeBase): pass boto3.dynamodb.conditions.Attr class Attr(AttributeBase): &quot;&quot;&quot;Represents an DynamoDB item&#39;s attribute.&quot;&quot;&quot; def ne(self, value): &quot;&quot;&quot;Creates a condition where the attribute is not equal to the value :param value: The value that the attribute is not equal to. &quot;&quot;&quot; return NotEquals(self, value) def is_in(self, value): &quot;&quot;&quot;Creates a condition where the attribute is in the value, :type value: list :param value: The value that the attribute is in. &quot;&quot;&quot; return In(self, value) def exists(self): &quot;&quot;&quot;Creates a condition where the attribute exists.&quot;&quot;&quot; return AttributeExists(self) def not_exists(self): &quot;&quot;&quot;Creates a condition where the attribute does not exist.&quot;&quot;&quot; return AttributeNotExists(self) def contains(self, value): &quot;&quot;&quot;Creates a condition where the attribute contains the value. :param value: The value the attribute contains. &quot;&quot;&quot; return Contains(self, value) def size(self): &quot;&quot;&quot;Creates a condition for the attribute size. Note another AttributeBase method must be called on the returned size condition to be a valid DynamoDB condition. &quot;&quot;&quot; return Size(self) def attribute_type(self, value): &quot;&quot;&quot;Creates a condition for the attribute type. :param value: The type of the attribute. &quot;&quot;&quot; return AttributeType(self, value) 두 class 모두 AttributeBase class를 사용하고 있었습니다!Key class는 AttributeBase class를 그대로 사용하고, Attr class는 몇 가지를 추가해서 사용하고 있었습니다. 그래서 만약 AttributeBase의 method를 사용할 때에는 두 class 모두 다 사용이 가능했던 것이었습니다.하지만 가독성을 고려해서 원래 목적에 맞게 사용하는 것이 좋을 것이라고 생각합니다." }, { "title": "pd.Series의 True 개수 구하기 속도 비교", "url": "/posts/pd_series_get_trues/", "categories": "Python", "tags": "Python", "date": "2021-08-04 00:00:00 +0900", "snippet": "pandas Series에서 True인 값의 개수를 구해야하는 상황에서 아래와 같은 4가지 방법들의 시간차이가 얼마나나는지 궁금해서 간단하게 테스트해보았습니다.테스트 결과, pd.Series는 numpy로 계산하는 것이 빨랐습니다.조건 sum: sum(ser) %%timeit sum(ser) len: len(ser[ser == True]) %%timeit len(ser[ser == True]) .sum: ser.sum() %%timeit ser.sum() count: ser.value_counts().loc[True] %%timeit ser.value_counts().loc[True] 테스트 ser = pd.Series([True, False] * 10) , len(ser) == 20 sum(): 2.02 µs ± 93 ns per loop len(): 107 µs ± 820 ns per loop .sum(): 26 µs ± 775 ns per loop .value_counts(): 252 µs ± 5.4 µs per loop ser = pd.Series([*([True, False] * 100000)]), len(ser) == 200000 sum(): 10.8 ms ± 259 µs per loop len(): 1.61 ms ± 30.2 µs per loop .sum(): 180 µs ± 6.38 µs per loop .value_counts(): 837 µs ± 11.8 µs per loop ser = pd.Series([*([False] * 199999), True]), len(ser) == 200000 sum(): 9.1 ms ± 224 µs per loop len(): 324 µs ± 2.41 µs per loop .sum(): 179 µs ± 2.72 µs per loop .value_counts(): 851 µs ± 18.5 µs per loop ser = pd.Series([*([True] * 199999), False]), len(ser) == 200000 sum(): 10.5 ms ± 346 µs per loop len(): 566 µs ± 13.1 µs per loop .sum(): 174 µs ± 1.32 µs per loop .value_counts(): 852 µs ± 11.2 µs per loop ser = pd.Series([*([True] * 100000), *([False] * 100000)]), len(ser) == 200000 sum(): 11 ms ± 188 µs per loop len(): 441 µs ± 5.33 µs per loop .sum(): 174 µs ± 2.11 µs per loop .value_counts(): 852 µs ± 14.7 µs per loop 결론 Series의 길이가 20000일 때, .sum()을 사용하는 것이 더 빠르게 측정되었습니다. 예상대로 numpy로 계산하는 것이 빨랐습니다. len의 경우 True의 위치에 따라 다르게 측정되었습니다. 계산하고자하는 타겟 series의 길이가 최대 100000 정도이므로 .sum()을 이용하였습니다." }, { "title": "np.isfinite(pd.Series) vs (pd.Series).notna() 비교", "url": "/posts/np_isfinite_vs_notna/", "categories": "Python", "tags": "Python", "date": "2021-08-04 00:00:00 +0900", "snippet": "numpy.isfinite()와 pandas.Series.notna()가 어떤 값들을 확인해주는지 궁금해서 비교해보았습니다. numpy.isfinite() infinity가 아니고 NaN이 아닌 값에 대해서 True를 반환합니다. np.isfinite(pd.Series([np.nan, np.inf, None, 0, 1, 100])) -&amp;gt; 0 False 1 False 2 False 3 True 4 True 5 True dtype: bool pandas.Series.notna() not NA인 값에 대해 True를 반환합니다. pd.Series([np.nan, np.inf, None, 0, 1, 100]).notna() -&amp;gt; 0 False 1 True 2 False 3 True 4 True 5 True dtype: bool pandas.Series.notna의 설명에 따르면 empty string이나 np.inf는 NA값으로 고려되지 않습니다. Characters such as empty strings “” or numpy.inf are not considered NA values (unless you set pandas.options.mode.use_inf_as_na = True). NA values, such as None or numpy.NaN, get mapped to False values. " }, { "title": "Git - 알아두면 좋을 것들", "url": "/posts/git_something_to_know/", "categories": "Tools", "tags": "Git", "date": "2021-06-10 00:00:00 +0900", "snippet": "bare repositorybare repo란?working directory를 가지지 않는 repository입니다. remote origin을 가지지 않으며 자신이 remote origin 역할을 수행합니다. bare repository의 이름은 .git으로 끝나도록 짓는 것이 일반적입니다. 만약 non-bare repository로 push를 시도한다면? → 아래와 같은 에러가 발생합니다. remote: error: By default, updating the current branch in a non-bare repository is denied, because it will make the index and work tree inconsistent with what you pushed, and will require &#39;git reset --hard&#39; to match the work tree to HEAD. bare repo 만들기 bare repository 만들기 git init --bare new_repo_name.git bare repository로 clone하기 git clone --bare my_project my_project.git SSH를 이용해 remote 공유하기SSH를 통해 공유할 수 있는 방법 두 가지을 알아보겠습니다. 사용자들의 개별 계정을 서버에 생성하고 OS의 권한설정을 통해 접근제어하기. 사용자들은 개인 계정으로 git repo에 접근해서 사용할 수 있습니다. 하나의 git 계정을 생성하고 사용자별로 SSH public key를 받아 ~/.ssh/authorized_keys에 추가하기. 사용자들은 git 계정을 통해서 git repo에 접근해서 사용할 수 있습니다. 하지만, 그냥 public key만 등록해서 git 계정으로 접속하면 git 명령어외에도 다른 작업들도 할 수 있습니다. 이를 제한하기 위해 추가적인 설정을 하였습니다. 방법1. forced command로 명령어 제한하기 ~/.ssh/authorized_keys에 public key를 아래처럼 등록하면 추가적인 기능을 제공합니다. command=&quot;git-shell -c \\&quot;$SSH_ORIGINAL_COMMAND\\&quot;&quot;,no-port-forwarding,no-agent-forwarding,no-X11-forwarding,no-pty ssh-rsa &amp;lt;ssh public key&amp;gt; &amp;lt;comment&amp;gt; $SSH_ORIGINAL_COMMAND값에 입력한 명령어가 들어갑니다. no-port-forwarding,no-agent-forwarding,no-X11-forwarding,no-pty 옵션을 통해 포트포워딩을 막을 수 있고 자세한 설명은 이곳에서 찾아볼 수 있습니다. 방법2. login shell을 git-shell로 변경하기 git-shell은 git과 관련된 명령어만 사용할 수 있도록 제한된 쉘입니다. 다음과 같이 설정할 수 있습니다. cat /etc/shells # see if git-shell is already in there. If not... sudo sh -c &quot;echo $(which git-shell) &amp;gt;&amp;gt; /etc/shells&quot; # and add the path sudo chsh -s $(command -v git-shell) &amp;lt;user&amp;gt; # change shell 이렇게 변경하면 su - git으로 git 계정으로 전환할 때도 git-shell을 기본적으로 사용해서 su --shell /bin/bash - git 등과 같이 shell을 변경해서 전환해야 합니다. Autocrlf 설정하기 core.autocrlf OS에 따라 다른 줄바꿈 문자 문제를 위해 아래와 같이 설정하여 사용합니다. 이렇게 하면 Windows에서는 CRLF를 사용하고 Mac, Linux, 저장소에서는 LF를 사용할 수 있습니다. Windows git config --global core.autocrlf true Linux, Mac git config --global core.autocrlf input merge할 때 fast-forward 끄기git merge의 fast-forword관련 기본 옵션은 --ff 로 merge commit을 생성하지 않고 branch pointer만 움직입니다.저는 필요한 경우가 아니라면 기록을 남기는 것을 선호해서 --no-ff 옵션을 통해 항상 merge commit을 생성하도록 하고 있습니다.참고자료 https://git-scm.com/book/en/v2/Git-on-the-Server-Getting-Git-on-a-Server https://git-scm.com/book/en/v2/Customizing-Git-Git-Configuration" }, { "title": "ClamAV", "url": "/posts/ClamAV/", "categories": "Ubuntu", "tags": "Ubuntu", "date": "2021-06-08 00:00:00 +0900", "snippet": " document https://www.clamav.net/documents view system log sudo zgrep CRON /var/log/syslog* view calmav logs less /var/log/clamav/clamav.log check config clamconf view docekr logs sudo docker logs fb8845be6263 diable clamav-daemon https://stackoverflow.com/questions/61496984/cant-stop-clamav-deamon-in-linux sudo systemctl stop clamav-daemon sudo systemctl disable clamav-daemon sudo systemctl status clamav-daemon sudo /etc/init.d/clamav-daemon stop Check for new database 0 times a day sudo vim /etc/clamav/freshclam.conf TestDatabases yes -&amp;gt; no Checks 24 -&amp;gt; Checks 0 sudo vim /etc/clamav/clamd.conf ScanMail true -&amp;gt; false ScanArchive true -&amp;gt; false SelfCheck 3600 -&amp;gt; 0 ScanPE true -&amp;gt; false ScanOLE2 true -&amp;gt; false ScanPDF true -&amp;gt; false ScanHTML true -&amp;gt; false ScanSWF true -&amp;gt; false ScanELF true -&amp;gt; false ScanXMLDOCS true -&amp;gt; false ScanHWP3 true -&amp;gt; false → ubuntu@camaro003:~$ sudo systemctl status clamav-daemon ● clamav-daemon.service - Clam AntiVirus userspace daemon Loaded: loaded (/lib/systemd/system/clamav-daemon.service; disabled; vendor preset: enabled) Drop-In: /etc/systemd/system/clamav-daemon.service.d └─extend.conf Active: inactive (dead) Docs: man:clamd(8) man:clamd.conf(5) https://www.clamav.net/documents/ Jun 09 01:45:51 camaro003 clamd[5179]: Wed Jun 9 01:45:51 2021 -&amp;gt; PDF support disabled. Jun 09 01:45:51 camaro003 clamd[5179]: Wed Jun 9 01:45:51 2021 -&amp;gt; SWF support disabled. Jun 09 01:45:51 camaro003 clamd[5179]: Wed Jun 9 01:45:51 2021 -&amp;gt; HTML support disabled. Jun 09 01:45:51 camaro003 clamd[5179]: Wed Jun 9 01:45:51 2021 -&amp;gt; XMLDOCS support disabled. Jun 09 01:45:51 camaro003 clamd[5179]: Wed Jun 9 01:45:51 2021 -&amp;gt; HWP3 support disabled. Jun 09 01:45:51 camaro003 clamd[5179]: Wed Jun 9 01:45:51 2021 -&amp;gt; Self checking disabled. Jun 09 01:46:03 camaro003 systemd[1]: Stopping Clam AntiVirus userspace daemon... Jun 09 01:46:05 camaro003 clamd[5179]: Wed Jun 9 01:46:05 2021 -&amp;gt; --- Stopped at Wed Jun 9 01:46:05 2021 Jun 09 01:46:05 camaro003 clamd[5179]: Wed Jun 9 01:46:05 2021 -&amp;gt; Socket file removed. Jun 09 01:46:05 camaro003 systemd[1]: Stopped Clam AntiVirus userspace daemon. clamd.conf options https://manpages.debian.org/jessie/clamav-daemon/clamd.conf.5.en.html " }, { "title": "CloudWatch agent", "url": "/posts/CloudWatch_agent/", "categories": "AWS", "tags": "AWS, CloudWatch", "date": "2021-06-03 00:00:00 +0900", "snippet": " EC2의 memory 사용량을 모니터링 하기 위해서 CloudWatch agent를 사용 docs: https://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html CloudWatchAgentServerPolicy권한을 가지는 Role를 생성 생성한 Role을 agent를 설치하고자하는 EC2에 연결 EC2 → Security → Modify IAM role → CloudWatchAgentServerPolicy을 가진 Role 선택 wget https://s3.amazonaws.com/amazoncloudwatch-agent/ubuntu/amd64/latest/amazon-cloudwatch-agent.deb : OS가 Ubuntu일 경우 해당 download-link를 사용 위에서 DEB 패키지를 다운로드한 경우 패키지가 있는 디렉터리에서 다음을 실행 sudo dpkg -i -E ./amazon-cloudwatch-agent.deb EC2의 아웃바운드 인터넷 액세스 권한 확인 → 현재 security group에서 아웃바운드 모두 허용 상태 Create the CloudWatch agent configuration file with the agent run sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-config-wizard ============================================================= = Welcome to the AWS CloudWatch Agent Configuration Manager = ============================================================= On which OS are you planning to use the agent? 1. linux 2. windows 3. darwin default choice: [1]: 1 Trying to fetch the default region based on ec2 metadata... Are you using EC2 or On-Premises hosts? 1. EC2 2. On-Premises default choice: [1]: 1 Which user are you planning to run the agent? 1. root 2. cwagent 3. others default choice: [1]: 1 Do you want to turn on StatsD daemon? 1. yes 2. no default choice: [1]: 2 Do you want to monitor metrics from CollectD? 1. yes 2. no default choice: [1]: 2 Do you want to monitor any host metrics? e.g. CPU, memory, etc. 1. yes 2. no default choice: [1]: 1 Do you want to monitor cpu metrics per core? Additional CloudWatch charges may apply. 1. yes 2. no default choice: [1]: 2 Do you want to add ec2 dimensions (ImageId, InstanceId, InstanceType, AutoScalingGroupName) into all of your metrics if the info is available? 1. yes 2. no default choice: [1]: 2 Would you like to collect your metrics at high resolution (sub-minute resolution)? This enables sub-minute resolution for all metrics, but you can customize for specific metrics in the output json file. 1. 1s 2. 10s 3. 30s 4. 60s default choice: [4]: 4 Which default metrics config do you want? 1. Basic 2. Standard 3. Advanced 4. None default choice: [1]: 1 Current config as follows: { &quot;agent&quot;: { &quot;metrics_collection_interval&quot;: 60, &quot;run_as_user&quot;: &quot;root&quot; }, &quot;metrics&quot;: { &quot;metrics_collected&quot;: { &quot;disk&quot;: { &quot;measurement&quot;: [ &quot;used_percent&quot; ], &quot;metrics_collection_interval&quot;: 60, &quot;resources&quot;: [ &quot;*&quot; ] }, &quot;mem&quot;: { &quot;measurement&quot;: [ &quot;mem_used_percent&quot; ], &quot;metrics_collection_interval&quot;: 60 } } } } Are you satisfied with the above config? Note: it can be manually customized after the wizard completes to add additional items. 1. yes 2. no default choice: [1]: 1 Do you have any existing CloudWatch Log Agent (http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html) configuration file to import for migration? 1. yes 2. no default choice: [2]: 2 Do you want to monitor any log files? 1. yes 2. no default choice: [1]: 2 Saved config file to /opt/aws/amazon-cloudwatch-agent/bin/config.json successfully. Current config as follows: { &quot;agent&quot;: { &quot;metrics_collection_interval&quot;: 60, &quot;run_as_user&quot;: &quot;root&quot; }, &quot;metrics&quot;: { &quot;metrics_collected&quot;: { &quot;disk&quot;: { &quot;measurement&quot;: [ &quot;used_percent&quot; ], &quot;metrics_collection_interval&quot;: 60, &quot;resources&quot;: [ &quot;*&quot; ] }, &quot;mem&quot;: { &quot;measurement&quot;: [ &quot;mem_used_percent&quot; ], &quot;metrics_collection_interval&quot;: 60 } } } } Please check the above content of the config. The config file is also located at /opt/aws/amazon-cloudwatch-agent/bin/config.json. Edit it manually if needed. Do you want to store the config in the SSM parameter store? 1. yes 2. no default choice: [1]: 2 Program exits now. Basic으로 설정시 mem_used_percent, disk_used_percent가 포함됨 agent 시작 sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -s -c file:/opt/aws/amazon-cloudwatch-agent/bin/config.json onpremise의 경우 sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m onPremise -s -c file:/opt/aws/amazon-cloudwatch-agent/bin/config.json /opt/aws/amazon-cloudwatch-agent/bin/config.json: config파일이 저장된 위치 → output: ****** processing amazon-cloudwatch-agent ****** /opt/aws/amazon-cloudwatch-agent/bin/config-downloader --output-dir /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.d --download-source file:/opt/aws/amazon-cloudwatch-agent/bin/config.json --mode ec2 --config /opt/aws/amazon-cloudwatch-agent/etc/common-config.toml --multi-config default Successfully fetched the config and saved in /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.d/file_config.json.tmp Start configuration validation... /opt/aws/amazon-cloudwatch-agent/bin/config-translator --input /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json --input-dir /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.d --output /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.toml --mode ec2 --config /opt/aws/amazon-cloudwatch-agent/etc/common-config.toml --multi-config default 2021/06/03 06:49:05 Reading json config file path: /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.d/file_config.json.tmp ... Valid Json input schema. I! Detecting run_as_user... No csm configuration found. No log configuration found. Configuration validation first phase succeeded /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent -schematest -config /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.toml Configuration validation second phase succeeded Configuration validation succeeded amazon-cloudwatch-agent has already been stopped Created symlink /etc/systemd/system/multi-user.target.wants/amazon-cloudwatch-agent.service → /etc/systemd/system/amazon-cloudwatch-agent.service. (optional) mem_used_percent만 기록되도록 config.json파일을 수정해서 fetch-config 함 추가정보 간격이 60초 미만인 데이터는 3시간 동안 유지도며 1분인 데이터는 15일 유지됨 https://aws.amazon.com/ko/cloudwatch/faqs/ Usage amazon-cloudwatch-agent-ctl -help " } ]
